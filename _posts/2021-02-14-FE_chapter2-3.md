---
layout: post
title:  "[FE for ML] 1.Fancy Tricks with Simple Numbers (3) 변환 분포 비교/확률 플롯"
subtitle: "[FE for ML] 1.Fancy Tricks with Simple Numbers (3) 변환 분포 비교/확률 플롯"
categories: data
tags: fe
mathjax: true
comments: true
---
<h3>Table of Contents<span class="tocSkip"></span></h3>
<div class="toc"><ul class="toc-item"><li><span><a href="#1.-변환-분포-비교-(원본,-로그,-Box-Cox)" data-toc-modified-id="1.-변환-분포-비교-(원본,-로그,-Box-Cox)-1">1. 변환 분포 비교 (원본, 로그, Box-Cox)</a></span></li><li><span><a href="#2.-확률-플롯(propbability-plot-/-probplot)" data-toc-modified-id="2.-확률-플롯(propbability-plot-/-probplot)-2">2. 확률 플롯(propbability plot / probplot)</a></span></li></ul></div>

본 포스팅은 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』의 내용을 바탕으로 구성하였으며 저의 주관적인 생각과 견해가 함께 서술되어 있습니다.


```python
# 사전 작업
import warnings
import matplotlib.pyplot as plt
warnings.filterwarnings(action='ignore')
plt.rcParams['axes.unicode_minus'] = False 
plt.rc('font', family='Malgun Gothic') 
```

<br>

---

### 1. 변환 분포 비교 (원본, 로그, Box-Cox)

지난 포스팅에서는 뉴스 기사의 원본 데이터 히스토그램과 로그 변환을 했을 때의 히스토그램을 살펴보았으며, log변환을 취했을 때 한 쪽으로 편향된 데이터의 히스토그램이 정규분포로 변환되는 것도 관측하였다. 또한 `분산 안정화 변환`에 관해서 간단히 다루었다.


이번 포스팅에서는 리뷰 데이터를 기반으로 `원본 데이터`와 `로그`, `Box-Cox`로 변환된 데이터들을 살펴보자. 먼저 지난번 포스팅 때 사용되었던 yelp데이터를 다시 로드하고 변환하도록 하자.


```python
import pandas as pd
import numpy as np
from scipy import stats
import json

biz_file = open('./example_data/archive/yelp_academic_dataset_business.json', encoding = 'utf-8-sig')
blz_df = pd.DataFrame([json.loads(x) for x in biz_file.readlines()])
biz_file.close()

# log변환
blz_df['log_review_count'] = np.log10(blz_df['review_count'] + 1)

# boxcox변환
rc_bc, bc_params = stats.boxcox(blz_df['review_count'])
blz_df['boxcox_review_count'] = rc_bc

blz_df[['review_count', 'log_review_count', 'boxcox_review_count']].head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_count</th>
      <th>log_review_count</th>
      <th>boxcox_review_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>36</td>
      <td>1.568202</td>
      <td>2.033597</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>0.698970</td>
      <td>1.096339</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>0.778151</td>
      <td>1.227901</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>0.602060</td>
      <td>0.910696</td>
    </tr>
    <tr>
      <th>4</th>
      <td>26</td>
      <td>1.431364</td>
      <td>1.936231</td>
    </tr>
  </tbody>
</table>
</div>



<br>

이렇게 변환된 데이터를 히스토그램으로 표현하면 다음과 같다.


```python
import matplotlib.pyplot as plt

fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (10, 8))

# 원본 리뷰 카운트 히스토그램
blz_df['review_count'].hist(ax = ax1, bins = 100)
ax1.set_yscale('log')
ax1.tick_params(labelsize=14)
ax1.set_title('Review Counts Histogram', fontsize=14)
ax1.set_xlabel('')
ax1.set_ylabel('Occurrence', fontsize = 14)

# 로그 변환된 리뷰 카운트
blz_df['log_review_count'].hist(ax = ax2, bins = 100)
ax2.set_yscale('log')
ax2.tick_params(labelsize=14)
ax2.set_title('Log Transformed Counts Histogram', fontsize=14)
ax2.set_xlabel('')
ax2.set_ylabel('Occurrence', fontsize = 14)

# Box-Cox 변환된 리뷰 카운트
blz_df['boxcox_review_count'].hist(ax = ax3, bins = 100)
ax3.set_yscale('log')
ax3.tick_params(labelsize=14)  
ax3.set_title('Box-Cox Transformed Counts Histogram', fontsize=14)
ax3.set_xlabel('')
ax3.set_ylabel('Occurrence', fontsize = 14)


plt.tight_layout()
```


![FE_chapter2-3_7_0](https://user-images.githubusercontent.com/53929665/107859876-d0540000-6e7f-11eb-8ba7-4ff99cfad44b.png)


히스토그램들을 확인했을 때, `로그`과 `box-cox` 변환된 데이터들은 정규분포를 나타내는 것처럼 보이지 않는다. 나는 처음에 이 부분에서 많은 혼란을 느꼈었다. 왜냐하면, 지금까지의 기억되는 지식들은 "xx변환을 취하면 한쪽으로 편향된 데이터가 정규분포와 비슷하게라도 형성됩니다."였다. 하지만 이처럼 `로그`변환이든 다른 제곱변환이든 루트변환이든 이러한 변환들은 마법같이 모든 분포를 정규분포로 변환 시켜주는 것은 아니다.

<br>

여기서 [이전 포스팅](https://jhryu1208.github.io/data/2021/02/08/FE_chapter2-2/)에서 공부했던 `분산 안정화 변환`에 관해서 한번 더 상기할 필요가 있다. `분산 안정화 변환`은 위에서 언급한 로그 변환, 루트 변환 등을 포괄했었다. 그리고 <u>변환되어진 변수의 분포가 정규분포에 가깝도록하는 이점</u>을 가지고 있었다. 여기서 주목해야할 점은 무조건 정규분포로 변환시키는 것이 아니라 가깝도록 변환시킨다는 점이다. 

<br>

위의 분포를 보아 정규분포에 가까운 것처럼 보이지도 않는다. 이를 확인하기 위해서는 `확률플롯(probability plot)`을 확인할 필요가 있다.


---

### 2. 확률 플롯(propbability plot / probplot)

`확률 플롯`은 연속형 자료에 대해서 특정 확률 모형을 상정하는 경우에 그 모형이 관측자료와 부합하는지 평가할 때 사용한다. 즉 쉽게 말하자면, 자료가 <u>특정분포(여기서는 정규분포를 의미)를 갖는지 확인하는 작업</u>이다. 확인은 `실험적인 분포`를 `이론적인 분포`와 비교하는 과정을 통해 이루어진다. 이는 본질적으로는 `이론적인 분위수`에 대한 `실제 관측된 분위수(즉 표본 분위수)`의 산점도에 해당한다. 

<br> 

어떻게 `확률 플롯`을 이용해서 `특정분포(정규분포)`임을 유추해낼 수 있는 것일까? 이를 알기 위해 먼저 `이론적 분위수`와 `표본 분위수`가 무엇인지에 관해서 알아야할 필요가 있다.

- <b>이론적 분위수(normal quantile)</b>
    - 분포(총 $n$개)를 순서대로 나열 했을 때, $i$ ($단, 1\leq i\leq n$)번째 값을 표준 정규 분포의 $100 * (\frac {i}{n+1}) \%$ 분위수로 변환한 값 
    - $\frac {i}{n+1}$ 대신에 $\frac {i-\frac{1}{2}}{n}$으로 주로 표현한다.



<img src="https://user-images.githubusercontent.com/53929665/107859003-42c1e180-6e7a-11eb-827e-c94cc54f0d6e.jpg" width="400" height="300">

- <b>표본 분위수 (sample quantile)</b>
    - 표본 정규 분포를 균일하게 $n$등분 했을 때의 분위수

<img src="https://user-images.githubusercontent.com/53929665/107859004-43f30e80-6e7a-11eb-8c2d-48ccc5360789.jpg" width="400" height="300">


(**핵심**) 이때, `이론적 분위수`와 `표본 분위수`의 분할 간격이 비슷하게 형성될 경우 확률플롯에 표시했을 때의 결과가 $y=x$에 유사해진다고한다. 즉 특정 데이터 분포가 정규분포를 따를수록 45도 기울기의 직선에 가까워진다. 따라서 `확률 플롯`은 정규분포를 판단하는 직관적인 근거를 제공한다는 것을 알 수 있다.

<br>

이제 위에서 변환시킨 yelp 리뷰 카운트 데이터셋의 `확률 플롯`을 확인해보자. 


```python
fig2, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (10, 10))

prob1 = stats.probplot(blz_df['review_count'], dist = stats.norm, plot = ax1)
ax1.set_xlabel('')
ax1.set_title('probplot against normal distribution')

prob2 = stats.probplot(blz_df['log_review_count'], dist = stats.norm, plot = ax2)
ax2.set_xlabel('')
ax2.set_title('Probplot after log transform')

prob3 = stats.probplot(blz_df['boxcox_review_count'], dist = stats.norm, plot = ax3)
ax3.set_xlabel('')
ax3.set_title('Probplot after Box-Cox transform')

plt.tight_layout()
```


![FE_chapter2-3_12_0](https://user-images.githubusercontent.com/53929665/107859878-d0ec9680-6e7f-11eb-82ec-ce4a504fe698.png)


먼저 처음으로 눈에 보이는 것은 변환된 데이터의 음의 영역 분위수는 일치하지 않는다는 것을 확인할 수 있다. 이는 왜냐하면 관측된 데이터가 전부 양수이며 가우시안은 음수일 수 있기 때문이다.

<br>

하지만, 변환된 데이터의 양의 분위수에 해당하는 꼬리는 일치하지는 않지만 정규분포에 가까워진 것을 확인할 수 있다.

<br>

그렇다면, 어떤 데이터에 로그변환을 했을 때 완벽에 가까운 정규분포를 얻을 수 있을까? 이전에 확인한 뉴스 기사 데이터를 다시 로드해보자.


```python
df = pd.read_csv('./example_data/OnlineNewsPopularity.csv')

fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize = (8, 10))

df[' n_tokens_content'].hist(ax=ax1, bins = 100)
ax1.tick_params(labelsize=14)
ax1.set_xlabel('Number of Words in Article', fontsize = 14)
ax1.set_ylabel('Number of Articles', fontsize = 14)
ax1.set_title('before log', fontsize = 14)

df['log_n_tokens_content'] = np.log10(df[' n_tokens_content']+1)
df['log_n_tokens_content'].hist(ax=ax2, bins = 100)
ax2.tick_params(labelsize=14)
ax2.set_xlabel('Log of Number of Words', fontsize = 14)
ax2.set_ylabel('Number of Articles', fontsize = 14)
ax2.set_title('after log', fontsize = 14)

prob3 = stats.probplot(df['log_n_tokens_content'], dist = stats.norm, plot = ax3)
ax3.set_xlabel('')
ax3.set_title('Probplot after log transform')

plt.tight_layout()
```


![FE_chapter2-3_14_0](https://user-images.githubusercontent.com/53929665/107859879-d1852d00-6e7f-11eb-99af-2602ae4fbbea.png)


해당 데이터셋에서는 로그변환을 했을 때, 리뷰 카운트 데이터셋과 달리 정규분포와 매우 흡사한 형태의 히스토그램 분포를 보이며, 확률플롯으로 나타내었을 때도 분위수의 음수 구간을 제외하고는 $y=x$와 거의 일치하는 형태를 보여주었다.

<br>

이유는 `로그 변환`의 경우 아래와 같은 `로그 정규분포(log normal distribution)`인 데이터에 적용해야 변환 후에 정규분포에 흡사한 결과가 나온다고 한다. 따라서, 완전히 왼쪽으로 극편향된 리뷰 카운트 데이터셋의 경우 로그 변환 이후에도 정규 분포와 가까워 졌을 뿐 흡사한 데이터로는 변환하지 못했던 것이다.

![300px-PDF-log_normal_distributions svg](https://user-images.githubusercontent.com/53929665/107859514-4dca4100-6e7d-11eb-9698-0de64a7eee54.png)


<br>

여담으로, 글쓴이의 경험상 로그 변환을 적용했음에도 불구하고 정규분포로 변환되지 않는 데이터 분포는 다른 제곱근 변환, 루트 변환, 1/y 변환 등 다른 변환으로도 정규분포로 변하지 않을 때가 있다. 이럴 경우는 마지막 정밀 수단인 Box-Cox변환을 이용하고, 이 또한 통하지 않았을 때는 `정규성 가정이 없는 비모수 검정`을 진행해야 한다고 한다.

<br>

---

### References

- Alice Zheng, Amanda Casari, 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』, O'Relly Media (2018)
- [wikipedia : Log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution)


