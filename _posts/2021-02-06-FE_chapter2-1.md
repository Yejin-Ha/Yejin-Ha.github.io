---
layout: post
title:  "[FE for ML] 1.Fancy Tricks with Simple Numbers (1) 도입 및 스칼라/벡터/공간"
subtitle: "[FE for ML] 1.Fancy Tricks with Simple Numbers (1) 도입 및 스칼라/벡터/공간"
categories: data
tags: fe
mathjax: true
comments: true
---
#### Table of Contents
<div class="toc"><ul class="toc-item"><li><span><a href="#1.Introduction" data-toc-modified-id="1.Introduction-1">1.Introduction</a></span></li><li><span><a href="#2.-스칼라,-벡터,-공간" data-toc-modified-id="2.-스칼라,-벡터,-공간-2">2. 스칼라, 벡터, 공간</a></span></li></ul></div>

본 포스팅은 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』의 내용을 바탕으로 구성하였으며 저의 주관적인 생각과 견해가 함께 서술되어 있습니다.

```python
# 사전 작업
import warnings
import matplotlib.pyplot as plt
warnings.filterwarnings(action='ignore')
plt.rcParams['axes.unicode_minus'] = False 
plt.rc('font', family='Malgun Gothic') 
```

---

### 1. Introduction

**좋은 피처**란?
- 데이터의 가장 두드러진 특징을 표현해야 한다.
- 구성하고자 하는 모델의 가정에도 적합해야 한다.
    
위를 만족하기 위해서는 종종 변환이 필요하며, 변환 중 가장 기본이 되는 것은 <u>숫자 피처 엔지니어링</u> 기법이다.

<br>

숫자 피쳐 엔지니어링을 진행하기 위한 세 가지 고려사항이 있다.
- 1.값의 크기 문제
- 2.피처의 스케일 문제
- 3.숫자 피처의 분포 문제

<br>

여기서 `2.피처의 스케일`은 모델(하단 예시)의 <u>출력에 가장 직접적인 영향</u>을 주게 된다.
- K-means clustering
- nearest neighbor
- RBF(Radial Basis Function) 와 Euclidean Distance을 기반으로하는 모델들

이러한 모델들은 예상된 스케일로 출력이 나오게 하려면 피쳐를 `정규화`해주는 것이 좋다. <br>

하지만, `논리함수` 모델의 경우 <u>입력 피처 스케일에 민감하지 않다</u>. 왜냐하면 입력이 무엇이든 이 함수의 출력은 binary이기 때문이다.
- Decision Tree Model(step function 기반)
- Random Forest
- Space Partitioning Tree

이러한 모델들은 따라서 입력스케일에 민감하지 않다.

<br>

선형 회귀 모델 등의 일부 모델에서 `3.입력 피처의 분포`는 가장 중요한 고려사항 중 하나에 속한다. 왜냐하면, 선형 회귀 모델의 학습 프로세스는 예측 오차가 가우시안 분포(혹은 normal distribution)와 같이 나타날 것으로 가정하기 때문이다. 이 가정은 일반적으로는 문제가 없지만, 예측 목표가 매우 큰 자릿수에 걸쳐 펼쳐질 경우 가우시안 오차 추정은 유효하지 않다. <br>

따라서, 이를 처리하기 위한 방법으로 <u>자릿수가 커지는 것을 방지하기 위해 목표변수를 변환하는 것</u>이다. 거듭제곱 변환의 한 유형인 `로그 변환`은 변수의 분포를 `가우시안 분포`에 가깝게 해준다.

<br>

---

### 2. 스칼라, 벡터, 공간

- 스칼라(scala) : 단일 숫자 피처
- 벡터(vector) : 방향이 있는 스칼라의 리스트
- 벡터 공간(vector space) : 벡터가 위치하는 공간

`피처 공간에서 데이터를 시각화`할 수 있듯이 `데이터 공간 내에서 피처를 시각화`할 수 있다!

- 예시
    - `피처 공간에서 데이터를 시각화` : xy축 = 인물의 성격 피처, data_point(데이터) = 인물의 이름
    - `데이터 공간 내에서 피처를 시각화` : xy축 = 인물의 이름, data_point(피처) = 인물의 성격 피처

<br>

---

###  References

- Alice Zheng, Amanda Casari, 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』, O'Relly Media (2018)

