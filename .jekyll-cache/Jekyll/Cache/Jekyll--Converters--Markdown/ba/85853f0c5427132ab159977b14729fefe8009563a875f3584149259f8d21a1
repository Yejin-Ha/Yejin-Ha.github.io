I"`<h4 id="ml-with-python-3-비지도-학습-알고리즘-2-3-t-sne-manifold-learning">[ML with Python] 3. 비지도 학습 알고리즘 (2-3) (T-SNE) Manifold Learning</h4>
<ul>
  <li>본 포스팅은 Manifold Learning에 관한 기본적인 내용에 관하여 다룹니다.</li>
  <li>확률적 임베딩(<code class="language-plaintext highlighter-rouge">SNE</code>)</li>
  <li>t-분포 확률적 임베딩(<code class="language-plaintext highlighter-rouge">t-SNE</code>)</li>
</ul>

<hr />

<p>필요 라이브러리 import</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'font'</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">'Malgun Gothic'</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h4 id="manifold-learning"><u>Manifold Learning</u></h4>

<ul>
  <li>주로 고차원 공간에 내제한 저차원 공간을 <code class="language-plaintext highlighter-rouge">Manifold</code>라한다.</li>
  <li>복잡한 매핑을 만들어 PCA보다 더 나은 시각화 제공</li>
  <li>해당 알고리즘의 목적은 대부분이 시각화라 3개 이상의 특성을 뽑는 경우가 드물다.</li>
  <li>훈련 데이터를 새로운 표현으로 변환시키지만 새로운 데이터에는 적용하지 못한다.
    <ul>
      <li>따라서, 테스트 세트에는 이용하지 못하고, 단지 훈련했던 데이터 변환만 가능하다.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Manifold hypothesis</code>
    <ul>
      <li>고차원 데이터가 있을 때, 고차원 데이터를 데이터 공간에 잘 뿌리면 <u>sample들을 잘 아우르는 subspace가 있을 것</u>이라는 가정</li>
      <li>고차원 데이터의 밀도는 낮지만, 이들의 집합을 포함하는 저차원의 Manifold가 있을 것이라는 가정
        <ul>
          <li>저차원 Manifold를 벗어나는 순간 밀도는 급격히 감소</li>
          <li>데이터의 차원 ⇧ ∝ 데이터의 공간 크기 ⇧⇧⇧ ∝ 동일 데이터의 밀도 ⇩⇩⇩⇩</li>
          <li>즉 차원이 증가할수록 데이터 분포 분석/모델추정에 필요한 샘플데이터의 개수⇧⇧</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://user-images.githubusercontent.com/53929665/102087977-9eadc100-3e5d-11eb-9e03-e0e9cbf7b770.png" alt="PNG 이미지 2020-12-14 13_34_32" /></p>

<p><br /></p>

<hr />

<h4 id="sne-stochastic-neighbor-embedding"><u>SNE (Stochastic Neighbor Embedding)</u></h4>

<p><code class="language-plaintext highlighter-rouge">Manifold</code>를 시작하기에 앞서 <code class="language-plaintext highlighter-rouge">t-분포 확률적 임베딩(t-SNE)</code>의 개념에 관하여 간단히 살펴볼 필요가 있었다. 일단 <code class="language-plaintext highlighter-rouge">t-분포 확률적 임베딩(t-SNE)</code>를 이해하기 위해서는 <code class="language-plaintext highlighter-rouge">확률적 임베딩(SNE)</code>부터 시작해야한다. <code class="language-plaintext highlighter-rouge">SNE</code>는 <u>고차원상에서의 데이터의 점 사이의 유클리드 거리를 유사성으로 나타내는 조건부 확률로 변환하는 것으로부터 시작</u>한다. <code class="language-plaintext highlighter-rouge">확률적 임베딩(SNE)</code>는 크게 다음과 같은 단계로 나뉘어진다. 다음의 과정들을 살펴보자.</p>

<p><br /></p>

<p><b>STEP 1</b><br />
고차원 공간 상에서 유사한 대상들은 이웃으로 선택될 확률이 높으며, 그렇지 않은 대상들은 이웃으로 선택될 확률이 낮아지도록 하는 유사도 확률 분포를 생성한다. 수식으로 표현하면 아래와 같다. 여기서 <code class="language-plaintext highlighter-rouge">p_j|i</code>는 주어진 대상 x_i가 있을 때 x_i의 이웃으로 x_j가 선택될 조건부 확률을 의미한다. <u>여기서 x_i가 이웃으로 선택될 확률의 분포는 다음과 같은 정규분포를 따른다고 가정</u>하게된다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">p_j|i</code> ⇧ ∝ 데이터 포인트가 가깝다.</li>
  <li><code class="language-plaintext highlighter-rouge">p_j|i</code> ⇩ ∝ 데이터 포인트가 멀다.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/53929665/102087983-a0778480-3e5d-11eb-917d-ddcfeaeb21cd.png" alt="PNG 이미지 2020-12-14 13_34_52" /></p>

<p><br /></p>

<p><b>STEP 2</b><br />
고차원 공간상에서의 대상들 간의 유사도 확률 분포의 차이를 최소화하기 위해서 저차원 공간상에서의 대상들 간에도 유사도 확률 분포를 정의한다. 수식으로 표현하면 다음과 같다. 여기서 y_i와 y_j는 각각 고차원 공간상의 대상 x_i, x_j에 대응하는 저차원 공간상에서의 대상을 의미한다. (여기서 조건부 확률의 계산에 사용되는 가우시안의 경우 분산 1/root(2)로 설정하게된다.)
<img src="https://user-images.githubusercontent.com/53929665/102087987-a1101b00-3e5d-11eb-98a4-b4ab01f137e8.png" alt="PNG 이미지 2020-12-14 13_35_10" /></p>

<p><br /></p>

<p><b>STEP 3</b><br />
STEP1과 STEP2 이후에 저차원 공간상에서 확률분포가 고차원 공간상에서 확률분포를 잘 대변하는지 확인하기 위해 <code class="language-plaintext highlighter-rouge">Kullback-Leibler Divergence</code>라는 지표를 사용한다. 만약 두 공간상에서의 분포가 비슷할수록 해당 지표는 0에 가까운 값을 가지게 된다. 마지막으로 해당 지표로 부터 도출되는 <code class="language-plaintext highlighter-rouge">비용함수(C)</code>를 최소화(<code class="language-plaintext highlighter-rouge">즉, 조건부 확률 p_j|i와 q_j|i가 근사하는 것을 목표로함</code>)하는 <code class="language-plaintext highlighter-rouge">q_j|i</code>를 기울기하강법으로 찾게되면 <code class="language-plaintext highlighter-rouge">SNE</code>과정이 마무리된다.
<img src="https://user-images.githubusercontent.com/53929665/102087991-a1101b00-3e5d-11eb-96ca-30e01b9338d1.png" alt="PNG 이미지 2020-12-14 13_35_31" /></p>

<p><br /></p>

<hr />

<h4 id="t-sne-t-distributed-stochastic-neighbor-embedding"><u>t-SNE (t-distributed stochastic neighbor embedding)</u></h4>

<p><code class="language-plaintext highlighter-rouge">t-SNE</code>는 <code class="language-plaintext highlighter-rouge">SNE</code>의 간단한 변형에 해당하며 <code class="language-plaintext highlighter-rouge">SNE</code>와의 차이점은 다음과 같다.</p>

<p><b><code class="language-plaintext highlighter-rouge">SNE</code>와의 차이점 1</b><br />
대칭점 간의 유사도를 대칭적으로 형성하기 위해서 다음과 같은 <code class="language-plaintext highlighter-rouge">대칭 형태의 확률 분포</code>를 사용한다.
<img src="https://user-images.githubusercontent.com/53929665/102087994-a1a8b180-3e5d-11eb-8763-112c1156dc9a.png" alt="PNG 이미지 2020-12-14 13_35_49" /></p>

<p><br /></p>

<p><b><code class="language-plaintext highlighter-rouge">SNE</code>와의 차이점 2</b><br /></p>

<p>위에서 고차원의 확률분포는 대칭 형태의 확률분포 <code class="language-plaintext highlighter-rouge">p_ij</code>를 사용하였다. 마찬가지로, 저차원 공간상에서의 확률분포 또한 <code class="language-plaintext highlighter-rouge">q_ij</code>라 지칭하며, <code class="language-plaintext highlighter-rouge">Kullback-Leibler Divergence</code>에서 <code class="language-plaintext highlighter-rouge">q_j|i</code>와 동일시 사용된다.
<img src="https://user-images.githubusercontent.com/53929665/102087995-a2414800-3e5d-11eb-9263-572fc16b8ca7.png" alt="PNG 이미지 2020-12-14 13_35_59" /></p>

<p><br /></p>

<p><b><code class="language-plaintext highlighter-rouge">SNE</code>와의 차이점 3</b><br />
<u>고차원에서 저차원 점으로 투영하게 될 경우, 거리의 멀고 가까움이 파괴될 가능성이 다분</u>하며 이를 <code class="language-plaintext highlighter-rouge">Crowding Problem</code>이라한다. 따라서 이를 방지하기 위해서는 <u>고차원에서 멀리 떨어진 점은 저차원에서는 더 멀게, 고차원에서 가까웠던 점은 저차원에서 더 가깝게 만들 필요</u>가 있다.</p>

<p><br /></p>

<p>이를 해결하기위해서 정규분포를 가정하던 기존의 방법과 달리 <code class="language-plaintext highlighter-rouge">Student-t</code>분포를 사용하여 결합 확률 <code class="language-plaintext highlighter-rouge">q_ij</code>를 다음과 같이 정의한다.</p>

<p><img src="https://user-images.githubusercontent.com/53929665/102087998-a2d9de80-3e5d-11eb-88bd-52f79a01fc06.png" alt="PNG 이미지 2020-12-14 13_36_09" /></p>

<p><br /></p>

<p>위와 같이 정의하게 될 경우, 기존의 꼬리가 얇고 길었던 정규분포의 그래프 형태에서 꼬리가 두꺼워진 <code class="language-plaintext highlighter-rouge">student-t</code>그래프의 형태로 변환하게 된다. 아래의 자료를 통해서 동일 자료에서 <code class="language-plaintext highlighter-rouge">정규분포</code>와 <code class="language-plaintext highlighter-rouge">student-t</code>그래프의 차이점에 관하여 직관적으로 파악할 수 있다.</p>

<p><br /></p>

<p>두 그래프를 비교하였을 때, 그래프가 겹치는 지점 사이 범위에서는 <code class="language-plaintext highlighter-rouge">student-t</code>의 q값(그림에서는 P(X))이 <code class="language-plaintext highlighter-rouge">정규분포</code>보다 저평가되고 있음을 확인 가능하다. 따라서, 동일 q값을 기준으로 가까운점의 값이 더 가까워 짐을 시각적으로 파악할 수 있다. 또한, 겹치는 지점의 외부 범위에서는 <code class="language-plaintext highlighter-rouge">studnet-t</code>의 q값이 <code class="language-plaintext highlighter-rouge">정규분포</code>보다 고평가되고 있음을 확인 가능하다. 따라서, 동일 q값을 기준으로 먼 점의 값이 더 멀어짐을 파악할 수 있다.</p>

<p><img src="https://user-images.githubusercontent.com/53929665/102092160-17634c00-3e63-11eb-86b3-0a8cc6533c7f.png" alt="PNG 이미지 2020-12-14 14_21_15" /></p>

<p><br /></p>

<hr />

<h4 id="t-sne를-이용한-매니폴드-학습"><u>t-SNE를 이용한 매니폴드 학습</u></h4>

<p><code class="language-plaintext highlighter-rouge">scikit-learn</code>에 있는 손글씨 숫자 데이터셋에 <code class="language-plaintext highlighter-rouge">t-SNE 매니폴드</code>학습을 적용해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                         <span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s">'xticks'</span><span class="p">:(),</span> <span class="s">'yticks'</span><span class="p">:</span> <span class="p">()})</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">digits</span><span class="p">.</span><span class="n">images</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/102097861-ca36a880-3e69-11eb-9c9e-6f2e999bac35.png" alt="ML_manifold_15_0" /></p>

<p><br /></p>

<p>비교를 위해서, 먼저 <code class="language-plaintext highlighter-rouge">PCA</code>를 이용해서 데이터를 2차원으로 축소화할 것이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PCA 모델을 생성합니다
</span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># 처음 두 개의 주성분으로 숫자 데이터를 변환합니다
</span><span class="n">digits_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">"#476A2A"</span><span class="p">,</span> <span class="s">"#7851B8"</span><span class="p">,</span> <span class="s">"#BD3430"</span><span class="p">,</span> <span class="s">"#4A2D4E"</span><span class="p">,</span> <span class="s">"#875525"</span><span class="p">,</span>
          <span class="s">"#A83683"</span><span class="p">,</span> <span class="s">"#4E655E"</span><span class="p">,</span> <span class="s">"#853541"</span><span class="p">,</span> <span class="s">"#3A3120"</span><span class="p">,</span><span class="s">"#535D8E"</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">digits_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> <span class="n">digits_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nb">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">digits_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> <span class="n">digits_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nb">max</span><span class="p">())</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)):</span>
    <span class="c1"># 숫자 텍스트를 이용해 산점도를 그립니다
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">digits_pca</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">digits_pca</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
             <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
             <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'weight'</span><span class="p">:</span> <span class="s">'bold'</span><span class="p">,</span> <span class="s">'size'</span><span class="p">:</span> <span class="mi">9</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"첫 번째 주성분"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"두 번째 주성분"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, '두 번째 주성분')
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/102097865-cb67d580-3e69-11eb-8fd2-e25da7c6b4ca.png" alt="ML_manifold_17_2" /></p>

<p>각 클래스가 어디에 있는지 살펴보기 위해 실제 숫자를 이용해 산점도를 그렸다. 0, 6, 4의 경우 비교적 잘 분리된 것 같지만, 중첩된 부분이 많이 관측된다.</p>

<p><br /></p>

<p>이제, <code class="language-plaintext highlighter-rouge">t-SNE</code>를 적용해 위의 결과와 비교해볼 것이다. 여기서 <code class="language-plaintext highlighter-rouge">t-SNE</code>는 새 데이터를 변환하는 기능을 제공하지 않기에<code class="language-plaintext highlighter-rouge"> transform</code> 매소드가 없다. 대신 <code class="language-plaintext highlighter-rouge">fit_transform</code>이 있다. (솔직히 이럴 것이면 왜 하나만 없는지 개인적으로 너무 궁금하다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># TSNE에는 transform 메소드가 없으므로 대신 fit_transform을 사용합니다
</span><span class="n">digits_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">digits_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> <span class="n">digits_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">digits_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> <span class="n">digits_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">)):</span>
    <span class="c1"># 숫자 텍스트를 이용해 산점도를 그립니다
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">digits_tsne</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">digits_tsne</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
             <span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">[</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
             <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'weight'</span><span class="p">:</span> <span class="s">'bold'</span><span class="p">,</span> <span class="s">'size'</span><span class="p">:</span> <span class="mi">9</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"t-SNE 특성 0"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"t-SNE 특성 1"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0, 0.5, 't-SNE 특성 1')
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/102097867-cb67d580-3e69-11eb-8ac6-8b2e4718c872.png" alt="ML_manifold_19_2" /></p>

<p><code class="language-plaintext highlighter-rouge">t-SNE</code>는 <code class="language-plaintext highlighter-rouge">PCA</code>와 비교될 정도로 모든 클래스가 확실히 잘 구분된 것을 확인할 수 있다(1과 9의 경우 좀 나뉘었지만 그룹으로 모여있기에 PCA와 확실히 비교된다).</p>

<hr />

<h3 id="references">References</h3>

<ul>
  <li>안드레아스 뮐러, 세라 가이도, 『파이썬 라이브러리를 활용한 머신러닝』, 박해선, 한빛미디어(2017)</li>
  <li><a href="https://terms.naver.com/entry.nhn?docId=5733143&amp;cid=60266&amp;categoryId=60266">네이버 지식백과 SNE</a></li>
  <li><a href="https://dos-tacos.github.io/paper%20review/TSNE/">dosc-tacos님의 github 블로그</a></li>
</ul>

:ET