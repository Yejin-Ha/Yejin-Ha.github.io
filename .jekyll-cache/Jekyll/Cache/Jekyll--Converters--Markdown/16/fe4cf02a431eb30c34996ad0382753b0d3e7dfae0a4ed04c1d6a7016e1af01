I"'7<h3>Table of Contents<span class="tocSkip"></span></h3>
<div class="toc"><ul class="toc-item"><li><span><a href="#1.-불용어" data-toc-modified-id="1.-불용어-1">1. 불용어</a></span></li><li><span><a href="#2.-빈도-기반-필터링" data-toc-modified-id="2.-빈도-기반-필터링-2">2. 빈도 기반 필터링</a></span><ul class="toc-item"><li><span><a href="#2-1.-빈출-단어" data-toc-modified-id="2-1.-빈출-단어-2.1">2-1. 빈출 단어</a></span></li><li><span><a href="#2-2-희귀-단어" data-toc-modified-id="2-2-희귀-단어-2.2">2-2 희귀 단어</a></span></li><li><span><a href="#2-3.-어간-추출" data-toc-modified-id="2-3.-어간-추출-2.3">2-3. 어간 추출</a></span></li></ul></li></ul></div>

<p>본 포스팅은 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』의 내용을 바탕으로 구성하였으며 저의 주관적인 생각과 견해가 함께 서술되어 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 사전 작업
</span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'axes.unicode_minus'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'font'</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">'Malgun Gothic'</span><span class="p">)</span> 
</code></pre></div></div>

<p><br /></p>

<hr />

<p>단어를 사용하여 데이터를 분석할 때, 의미있는 단어와 의미없는 잡음 단어를 깨끗하게 분리하기 위한 필터링 수단에 관하여 알아보자.
<br /></p>

<h3 id="1-불용어">1. 불용어</h3>

<p><code class="language-plaintext highlighter-rouge">불용어 리스트</code>를 이용해서 의미 없는 피처를 생성하는 잡음 단어들을 제거할 수 있다.</p>

<p><br /></p>

<p>그렇다면 <strong><code class="language-plaintext highlighter-rouge">불용어(stopword)</code></strong>란 무엇일까?</p>
<ul>
  <li>I, on, the, me, 조사, 접미사와 같이 문장에서 자주 등장하지만 <u>제외시켜도 문장의 의미를 바꾸지 않는 요소</u> 혹은 자주 등장하지만 <u>실제적으로는 문장을 분석하는데 있어서 큰 영향을 주지 않는 단어</u>들을 의미한다.
    <ul>
      <li>위와 같은 대명사/관사/전치사는 <code class="language-plaintext highlighter-rouge">분류</code>작업에서는 가치가 크지않다. 하지만, 정해진 규칙이 없어 의미를 예측하기 힘든 비정형 데이터를 분석하기 위한 <strong>감성분석(sentiment analysis)</strong>에서는 가치있을 수 있다. (여기서는 감성분석에 관해서 다루지 않는다)</li>
      <li>파이썬의 <code class="language-plaintext highlighter-rouge">NLP</code>패키지인 <code class="language-plaintext highlighter-rouge">NLTK</code>는 많은 언어학자들이 정의한 <code class="language-plaintext highlighter-rouge">불용어 리스트</code>를 가지고 있다. (안타깝지만 한글은 절레절레…)</li>
      <li>ex) a, about, above, am, an, been, didn’t, couldn’t, i’d, i’ll, itself, let’s, myself, our, they …</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p>또 다른 잡음 필터링 방법으로는 <strong><code class="language-plaintext highlighter-rouge">상용어(common word)</code></strong>를 사용하는 <strong>통계적인 방법</strong>도 존재한다.</p>

<p><br /></p>

<p>(*상용어 : 일상에서 자주 쓰이는 언어)</p>

<p><br /></p>

<hr />

<h3 id="2-빈도-기반-필터링">2. 빈도 기반 필터링</h3>

<h4 id="2-1-빈출-단어">2-1. 빈출 단어</h4>

<p>얼마나 단어가 카운팅되는지 확인하는 <code class="language-plaintext highlighter-rouge">빈도 통계</code>를 이용하게되면 <code class="language-plaintext highlighter-rouge">상용어</code>혹은 <code class="language-plaintext highlighter-rouge">불용어</code>인 단어를 필터링하기에 유용하다. 하지만, <strong><u>특정 단어가 너무 많이 카운팅될 경우 의미를 파악하기 어려울 수 있다</u></strong>. 예를 들어, 케나다의 의사 회의록에서는 “House of Commons(하원)”이라는 문구가 많기 때문에 “House”라는 단어의 카운팅이 높다. 하지만, “House of Commons”에서의 “House”는 우리가 생각하는 일반적인 “집”을 의미하지 않는다.</p>

<p><br /></p>

<p>이처럼 “House”와 같은 일반적으로는 의미를 가지고 있지만, 특정 corpus(ex.”House of Commons”)에서는 그렇지 않은 단어같이 <strong>corpus에 종속적인 단어</strong>들은 <code class="language-plaintext highlighter-rouge">빈도 통계</code>를 이용해 구분해내기 힘들다.</p>

<p><br /></p>

<p>이런 구분해내기 힘든 단어들을 어떻게 처리할지 생각하는 것도 꽤나 고난에 해당한다. 하지만, 단점만 있는 것은 아니다. 1)가장 빈번하게 나오는 단어를 살펴봄으로써 파싱 문제를 서치할 수 있고, 2)빈출이 가장 많이 되는 단어에 초점을 맞추어 문서를 효율적으로 확인할 수 있다.</p>

<p><br /></p>

<h4 id="2-2-희귀-단어">2-2 희귀 단어</h4>

<p>목적에 따라서 <code class="language-plaintext highlighter-rouge">희귀 단어</code>를 필터링 하는 경우도 있다.</p>

<p><br /></p>

<p><strong><code class="language-plaintext highlighter-rouge">희귀 단어</code></strong>란?</p>
<ul>
  <li>정말 잘 알려지지 않은 단어</li>
  <li>철자가 틀린 단어 등…</li>
  <li>통계적 모델에서는 소수의 문서에서 나오는 unique한 단어에 해당하기에 유용하기보다는 잡음에 가깝다.</li>
</ul>

<p><br /></p>

<p>이러한 <code class="language-plaintext highlighter-rouge">희귀 단어</code>들은 모델의 연산량과 저장 비용을 증가 시킬 뿐더러, 분류와 같은 작업에서도 문제를 일으킬 수 있다.</p>

<blockquote>
  <p>이전에 계속 사용해왔던 Yelp 데이터셋의 경우<br />
160만개의 리뷰 중에서 357,481개의 고유 단어가 내제되어있으며, 378,481개라는 고유 단어 중 189,915개는 하나의 리뷰에만 나타나며, 41,162개의 단어는 오로지 한 두개의 리뷰에서만 나타난다고 한다.<br />
<br />
즉 고유 단어 중 60% 이상이 희귀 단어에 속한다고 볼 수 있다. 즉 많이 나오는 단어의 갯수는 적고, 드물게 나타나는 단어의 갯수가 많다는 것이다. <br />
<br />
이런 단어 데이터셋을 그대로 분류 모델에 적용할 시 과적합은 물론이고 계산 오버헤드도 유발할 것이다.</p>
</blockquote>

<p><br /></p>

<p>이처럼 데이터 사용자를 불편하게 만드는 <code class="language-plaintext highlighter-rouge">희귀 단어</code>는 다행히 <strong>단어 카운트 통계</strong>를 기반으로 쉽게 식별하고 정리할 수 있다. 또한 <code class="language-plaintext highlighter-rouge">희귀 단어</code> 카운트는 나중에 사용할 수 있도록 <code class="language-plaintext highlighter-rouge">휴지통(garbage bin)</code>에 모아 놓을 수 있다.</p>

<p><br /></p>

<p>더불어, 텍스트 문서가 매우 짧은 경우에는 해당 문서에는 유용한 정보가 없을 가능성이 높기 때문에 모델을 학습시킬 때 사용하지 않는 것이 좋다. 하지만, 트위터는 본질적으로 글이 짧기에 다른 피처 생성 기법 및 모델링 기법을 필요로 한다.</p>

<p><br /></p>

<h4 id="2-3-어간-추출">2-3. 어간 추출</h4>

<p>일련의 문자열을 의미있는 토큰으로 분해하고 BoW를 만드는 파싱 과정에서는 한 가지의 문제점이 있다. 그것은 “flower”과 “flowers”, “swimmer”와 “swim”같은 <strong><u>동일한 단어의 여러가지 변형이 별도로 카운트 된다는 점</u></strong>이다.</p>

<p><br /></p>

<p>“swimmer”, “swimming”, “swim” 모두 품사적으로는 모두 다르지만 단어의 의미는 서로가 매우 비슷하다. 따라서, <strong><u>단어의 여러 변형을 모두 하나의 동일한 어간(stem)으로 매핑</u></strong>되는 것이 좋을 수 있다.</p>

<p>(*어간 : 단어를 활용할 때 변하지 않는 부분)</p>

<p><br /></p>

<p>위와 같이 동일한 <code class="language-plaintext highlighter-rouge">어간</code>으로 매핑하는 작업을 <strong><code class="language-plaintext highlighter-rouge">어간 추출(stemming)</code></strong>이라 부르며, 모든 단어의 기본이 되는 언어학적인 어근 형태로 잘라내는 NLP작업이다. 일부는 언어학적 규칙에 기반하며, 또 일부는 통계학에 기반을 둔다.</p>

<p>(*어근 : 단어의 중심이 되는 형태소)</p>

<p><br /></p>

<p>대부분 어간 추출 도구는 영어에 집중되어 있다. 그중 많이 사용되는 <strong><code class="language-plaintext highlighter-rouge">포터 어간 추출기(Porter Stemmer)</code></strong>는 영어에 대한 무료 어간 추출 도구다. 다음은 <code class="language-plaintext highlighter-rouge">NTLK</code>파이썬 패키지를 통해 포터 어간 추출기를 실행하는 예제이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 만약 nltk모듈이 없다고 에러가 뜨면 다음을 수행하자
# import sys
# !{sys.executable} -m pip install nltk
</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">stem</span><span class="p">.</span><span class="n">porter</span><span class="p">.</span><span class="n">PorterStemmer</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'flowers :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'flowers'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'zero :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'zeros'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'stemmer :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'stemmer'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'sixties :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'sixties'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'sixty :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'sixty'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'goes :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'goes'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'go :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'go'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'news :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'news'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'new :'</span><span class="p">,</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="s">'new'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>flowers : flower
zero : zero
stemmer : stemmer
sixties : sixti
sixty : sixti
goes : goe
go : go
news : news
new : new
</code></pre></div></div>

<p>위의 예제에서 확인할 수 있듯이 많은 경우를 처리할 수 있지만 “goes”와 같이 완벽하지 않은 케이스들이 존재한다ㅠㅠ. 또한, 위의 분류기에서는 제대로 분류되었지만, “news”와 “new”는 서로 다른 의미를 가지고 있지만 두 단어의 동일 어간은 “new”이다. 이와 비슷한 예는 많이 존재한다. 그러므로 <strong><u>어간 추출이 항상 사용되어져야만 한다는 것은 아니라는 점을 기억해 두는 것이 좋다.</u></strong></p>

<p><br /></p>

<hr />

<h3 id="references">References</h3>

<ul>
  <li>Alice Zheng, Amanda Casari, 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』, O’Relly Media (2018)</li>
</ul>

:ET