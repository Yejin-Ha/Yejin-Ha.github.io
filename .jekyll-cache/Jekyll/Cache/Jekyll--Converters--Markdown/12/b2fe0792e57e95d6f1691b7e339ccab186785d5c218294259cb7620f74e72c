I"4<h3>Table of Contents<span class="tocSkip"></span></h3>
<div class="toc"><ul class="toc-item"><li><span><a href="#1.-파싱과-토큰화" data-toc-modified-id="1.-파싱과-토큰화-1">1. 파싱과 토큰화</a></span></li><li><span><a href="#2.-구문-탐색을-위한-연어-추출" data-toc-modified-id="2.-구문-탐색을-위한-연어-추출-2">2. 구문 탐색을 위한 연어 추출</a></span><ul class="toc-item"><li><span><a href="#2-1.-빈도-기반-방법-(비추천)" data-toc-modified-id="2-1.-빈도-기반-방법-(비추천)-2.1">2-1. 빈도 기반 방법 (비추천)</a></span></li><li><span><a href="#2-2.-연어-추출을-위한-가설-검증" data-toc-modified-id="2-2.-연어-추출을-위한-가설-검증-2.2">2-2. 연어 추출을 위한 가설 검증</a></span></li><li><span><a href="#2-3.-청킹과-품사-태깅" data-toc-modified-id="2-3.-청킹과-품사-태깅-2.3">2-3. 청킹과 품사 태깅</a></span></li></ul></li></ul></div>

<p>본 포스팅은 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』의 내용을 바탕으로 구성하였으며 저의 주관적인 생각과 견해가 함께 서술되어 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 사전 작업
</span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'axes.unicode_minus'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'font'</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">'Malgun Gothic'</span><span class="p">)</span> 
</code></pre></div></div>

<p><br /></p>

<hr />

<p><code class="language-plaintext highlighter-rouge">문자열</code>을 <code class="language-plaintext highlighter-rouge">단어의시퀀스</code>로 변환시키는 방법(<code class="language-plaintext highlighter-rouge">파싱(parsing)</code>, <code class="language-plaintext highlighter-rouge">토큰화(tokenization)</code>)에 관해서 살펴보자.</p>

<p><br /></p>

<h3 id="1-파싱과-토큰화">1. 파싱과 토큰화</h3>

<ul>
  <li>문자열에 text이외의 것이 포함되어 있는 경우가 있다.
    <ul>
      <li>이런 case에서 필요한 것이 <strong><code class="language-plaintext highlighter-rouge">파싱</code></strong>이다.</li>
      <li><strong>문서</strong>의 종류에 따라 관심없는 부분을 처리할 방법을 결정해야만 한다.
        <ul>
          <li>ex1) (문서 : 웹페이지) =&gt; URL : 의미없기에 처리</li>
          <li>ex2) (문서 : 이메일) =&gt; From, To, Subject : 의미를 구분해주기에 특별 처리</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>간단한 <code class="language-plaintext highlighter-rouge">파싱</code>후에는 일반 <strong>문서</strong> text 부분은 <strong><code class="language-plaintext highlighter-rouge">토큰화</code></strong>를 수행할 수 있다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">토큰화</code> : 글자의 시퀀스인 <code class="language-plaintext highlighter-rouge">문자열</code>을 <code class="language-plaintext highlighter-rouge">토큰의 시퀀스</code>를 변환</li>
      <li><code class="language-plaintext highlighter-rouge">토큰</code> : 각 토큰은 하나의 단어로서 카운트된다.</li>
      <li>토큰화 유용 구분자 : 공백 문자, 구두점(마침표, 쉼표)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p>때로는 <code class="language-plaintext highlighter-rouge">전체 문서</code> 대신 <code class="language-plaintext highlighter-rouge">문장</code>을 분석해야하는 경우도 있다.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">n-grams</code>로 $n$개의 토큰을 생성할 경우</strong> <code class="language-plaintext highlighter-rouge">문서</code>가 아닌 <code class="language-plaintext highlighter-rouge">문장</code>단위로 수행되어져야 한다.
    <ul>
      <li>즉, 문장 단위로 수행할 때 마침표(.)는 중요한 지표가 된다.</li>
      <li>하지만,<code class="language-plaintext highlighter-rouge">word2vec</code>와 같이 복잡한 피쳐 생성 기법은 <code class="language-plaintext highlighter-rouge">문장</code>이나 <code class="language-plaintext highlighter-rouge">단락</code>에 적용하는 경우가 있다.</li>
      <li>따라서, <code class="language-plaintext highlighter-rouge">문서 -&gt;(파싱)-&gt; 문장 -&gt;(토큰화)-&gt; 단어</code>에서 상황에 따라 필요한 것을 사용하도록 하자.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<hr />

<h3 id="2-구문-탐색을-위한-연어-추출">2. 구문 탐색을 위한 연어 추출</h3>

<p>우선 <strong><code class="language-plaintext highlighter-rouge">연어(collocation)</code></strong>란?</p>
<ul>
  <li>어떤 것을 지칭하는 관습적인 방식에 부합하는 두 개 이상의 단어로 구성된 표현
    <ul>
      <li>ex1) 연어인 경우 : <br /> “strong tea : 진한 차” ≠ strong(큰 물리적인 힘) + tea(차)</li>
      <li>ex2) 연어가 아닌 경우 : <br />“cute puppy : 귀여운 강아지” = cute(귀여운) + puppy(강아지)</li>
    </ul>
  </li>
  <li>우리말로 생각해보면, 따로 쓰면 의미를 잃어버리는 구문을 의미한다.
    <ul>
      <li>ex) “학창 시절”, “연인 사이” 등</li>
    </ul>
  </li>
  <li>연어는 연속일 수도 있고 아닐 수도 있다. 따라서 반드시 연속적인 시퀀스를 가져야할 필요는 없다.
    <ul>
      <li>따라서 모든 연어가 <code class="language-plaintext highlighter-rouge">n-grams</code>인 것은 아니다.</li>
      <li>ex) Emma Knocked on the door =&gt; 연어 : “Knock Door” ∉ n-grams</li>
    </ul>
  </li>
</ul>

<p>그러므로 <code class="language-plaintext highlighter-rouge">연어</code>를 <code class="language-plaintext highlighter-rouge">카운팅</code>을 통해 연어인 구문의 의미를 정확히 그리고 적절하게 잡아낼 수 없다. 따라서 <code class="language-plaintext highlighter-rouge">연어</code>를 텍스트에서 서치하기 위해 다음의 방법들을 사용한다.</p>

<ul>
  <li>1) 텍스트에서 사용되어진 <code class="language-plaintext highlighter-rouge">연어</code>를 미리 정의
    <ul>
      <li>많은 노력이 필요하겠지만 효과는 발군일 것이다.</li>
      <li>But, 많은 수작업 및 지속적 업데이트가 진행되어져야만 한다.</li>
      <li>따라서 현실적이지는 않다…</li>
    </ul>
  </li>
  <li>2) <strong>통계적 방법론</strong>
    <ul>
      <li>NLP등장 이후 구문을 찾기 위해 위와 같은 수작업인 방법보다는 통계적인 방법론이 더 많이 선택되어지고 있다.</li>
    </ul>
  </li>
</ul>

<h4 id="2-1-빈도-기반-방법-비추천">2-1. 빈도 기반 방법 (비추천)</h4>

<p>해당 방법은 가장 단순한 방법이다. 단지 <u>가장 빈번하게 나타나는 </u><code class="language-plaintext highlighter-rouge">n-grams</code><u>를 살펴보는 것이다</u>. 하지만, 가장 빈번하게 나타나는 것은 이전에도 확인했듯이 가장 유용하지 않을 수 있다는 리스크가 크다. 예를 들자면, 문장에서 가장 많이 확인할 수 잇는 “주어+동사”구문이 이에 해당할 것이다. 특히 3인칭 소설의 경우 연어라고 볼 수 없는 “I am”, “I was” 등이 2-grams로 나타냈을 때 가장 많이 카운팅 될 것이다.</p>

<p><br /></p>

<h4 id="2-2-연어-추출을-위한-가설-검증">2-2. 연어 추출을 위한 가설 검증</h4>

<p>해당 기법에서의 핵심은 <strong><u>두 단어가 우연히 만날 확률보다 더 자주 함께 나타나는 묻는 것</u></strong>이다. 이 질의에 답하기 위해서는 <code class="language-plaintext highlighter-rouge">가설 검증( hypothesis test)</code>를 진행해야만 한다.</p>

<p><br /></p>

<p><strong><code class="language-plaintext highlighter-rouge">가설 검증</code></strong>이란?</p>
<ul>
  <li>잡음이 많은 데이터를 “YES”혹은 “NO”로 정제하는 방법이다.</li>
  <li><strong>무작위 분포에서 추출한 표본</strong>을 통해 데이터를 모델링하는 과정도 포함된다.
    <ul>
      <li>따라서 검증을 위한 답은 항상 <strong>확률</strong>로 표현될 것이다.</li>
      <li>가설 검증 결과 예시 : <br />이 두데이터셋은 95%의 확률로 동일한 분포로 부터 나왔다고 할 수 있다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p>책에서 설명되어지는 <code class="language-plaintext highlighter-rouge">연어 추출</code>에 대한 가설 검증은 <code class="language-plaintext highlighter-rouge">우도 비율 검정(likelihood ratio test)</code>를 기반으로 한다.</p>

<p><br /></p>

<p><strong><code class="language-plaintext highlighter-rouge">우도 비율 검정</code></strong>이란?</p>

<ul>
  <li>두 단어 쌍에 대해서 이 기법은 관측된 데이터셋에서 <strong>두 가지 가설</strong>을 테스트하는 과정
    <ul>
      <li><code class="language-plaintext highlighter-rouge">귀무가설</code>
        <ul>
          <li>설정한 가설이 진실할 확률이 극히 적어 처음부터 버려질 것이라 예상하는 가설</li>
          <li>$word1$이 $word2$와 <strong>독립적</strong>으로 나타날 것이다.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">대립가설</code>
        <ul>
          <li>귀무가설이 기각되어졌을 때, 받아들여지는 대체가설</li>
          <li>즉, 귀무가설과 달리 실제 검증 대상이 아니며 단순히 귀무가설이 기각되면 채택되어지는 가설</li>
          <li>$word1$이 보이는 것은 $word2$를 보게 될 가능성을 <strong>변화 시킬 것</strong>이다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p><code class="language-plaintext highlighter-rouge">연어</code>추출을 위한 <code class="language-plaintext highlighter-rouge">우도 비율 검정</code>의 경우 다음과 같은 질문을 제기할 것이다.</p>

<blockquote>
  <p>주어진 corpus에서 해당 단어의 <strong>발생 빈도</strong>는 아래의 두 모델 중 어느 쪽이 더 높을 까?</p>
  <ul>
    <li>귀무가설 : 두 단어가 독립적으로 발생하는 모델</li>
    <li>대립가설 : 두 단어의 발생 확률이 얽혀 있는 모델</li>
  </ul>
</blockquote>

<p>각 가설은 다음의 수식으로 표현할 수 있다.</p>
<ul>
  <li>귀무가설 $H_{null}$  <br />
  \(P(w_2|w_1) = P(w_2|{w_1}^c)\)</li>
  <li>대립가설 $H_{alternate}$  <br />
  \(P(w_2|w_1) ≠ P(w_2|{w_1}^c)\)</li>
</ul>

<p>최종 통계값인 이 둘의 <strong>우도 비율 검정 통계량에 대한 로그</strong>는 다음과 같다.</p>
<ul>
  <li>여기서 우도 함수 $L(Data;H)$는 단어 쌍에 대한 <strong>독립</strong>혹은 <strong>비독립</strong> 모델에서 데이터셋 내에 단어가 나타날 빈도의 확률의 의미한다.</li>
</ul>

\[\logλ = \log\frac{L(Data;H_{null})}{L(Data;H_{alternate})}\]

<p><br />(아직은 확실히 이해하지 못했다 조금 더 통계에 관해서 숙련도를 쌓은 뒤 다시 알아봐야겟다 ㅠ.ㅠ 지금은 이런게 있다! 정도로만 알고 넘어가야겠다…)</p>

<p><br /></p>

<h4 id="2-3-청킹과-품사-태깅">2-3. 청킹과 품사 태깅</h4>

<p><strong><code class="language-plaintext highlighter-rouge">청킹</code></strong> 이란?</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">청크</code> 단위로 묶어 이해하는 과정을 <code class="language-plaintext highlighter-rouge">청킹</code>이라 한다.
    <ul>
      <li>청크 : 머리 속에서 1개의 덩어리로 취급되는 단어 개념</li>
    </ul>
  </li>
  <li>품사를 기반으로 토큰 시퀀스를 형성, 이런 면에서 <code class="language-plaintext highlighter-rouge">n-grams</code>보다 좀 더 정교하다</li>
  <li>품사로 각 단어를 토큰화한 후에 품사 그룹 또는 청크를 찾기 위해 토큰들을 검사한다.</li>
  <li>이와 같이 단어와 품사를 매핑하는 모델은 일반적으로 언어에 종속적이다.</li>
</ul>

<p><br /></p>

<hr />

<h3 id="references">References</h3>

<ul>
  <li>Alice Zheng, Amanda Casari, 『Feature Engineering for Machine Learning - PRRINCIPLES AND TECHNIQUES FOR DATA SCIENTISTS』, O’Relly Media (2018)</li>
</ul>

:ET