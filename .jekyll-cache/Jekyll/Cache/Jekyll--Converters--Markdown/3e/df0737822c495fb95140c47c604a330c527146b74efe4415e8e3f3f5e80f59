I"<<h4 id="ml-with-python-2-지도-학습-알고리즘-요약-및-정리">[ML with Python] 2. 지도 학습 알고리즘 요약 및 정리</h4>
<p>많은 알고리즘에서 좋은 성능을 내려면 <code class="language-plaintext highlighter-rouge">매개변수</code>를 적절히 설정하는 것이 중요하다. 어떤 알고리즘은 입력 데이터에 대해, 특히 <code class="language-plaintext highlighter-rouge">입력 특성의 스케일을 어떻게 하느냐</code>에 민감하다. 그러므로 모델의 가정과 매개변수의 의미를 이해하지 못하고 데이터셋에 아무 알고리즘이나 무조건 적용하면 좋은 모델을 만들 가능성이 낮다.</p>

<p><br /></p>

<p><b>새로운 데이터셋으로 작업할 때</b>는 <code class="language-plaintext highlighter-rouge">선형 모델</code>이나 <code class="language-plaintext highlighter-rouge">나이브 베이즈</code> 혹은 <code class="language-plaintext highlighter-rouge">최근접 이웃 모델</code>같은 간단한 모델로 시작해서 성능이 얼마나 나오는지 가늠해 보는 것이 좋다. 데이터를 충분히 이해한 뒤에 <code class="language-plaintext highlighter-rouge">랜덤 포레스트</code>나 <code class="language-plaintext highlighter-rouge">그레디언트 부스팅</code>, 그리고 <code class="language-plaintext highlighter-rouge">신경망</code> 같은 복잡한 모델을 만들 수 있는 알고리즘을 고려해 볼 수 있다.</p>

<hr />

<ul>
  <li><a href="https://jhryu1208.github.io/data/2020/10/25/SUPERVISED_LEARNING_1_k-NN.md/"><b><code class="language-plaintext highlighter-rouge">최근접 이웃</code></b> </a>
    <ul>
      <li>작은 데이터셋에 유용</li>
      <li>기본 모델로서 좋고 설명하기 쉬움</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/10/linear_model_LinearRegression/"><b><code class="language-plaintext highlighter-rouge">선형 모델</code></b></a>
    <ul>
      <li>대용량 데이터셋에 유용</li>
      <li>고차원 데이터에 가능</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/14/naive_bayes/"><b><code class="language-plaintext highlighter-rouge">나이브 베이즈</code></b></a>
    <ul>
      <li>분류만 가능</li>
      <li>선형 모델보다 훨씬 빠르다, 하지만 선형 모델 보다 덜 정확하다.</li>
      <li>대용량 데이터셋과 고차원 데이터에 사용 가능</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/15/ML_decision_tree/"><b><code class="language-plaintext highlighter-rouge">결정 트리</code></b></a>
    <ul>
      <li>매우 빠르다</li>
      <li>데이터 스케일 조정이 필요없다</li>
      <li>시각화하기좋고 설명하기 쉽다</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/16/ML_decision_tree_ensemble_random_forest/"><b><code class="language-plaintext highlighter-rouge">랜덤 포레스트</code></b></a>
    <ul>
      <li>결정 트리보다 좋은 성능을 낸다.</li>
      <li>매우 안정적이고 강력하다.</li>
      <li>데이터 스케일 조정이 필요 없다.</li>
      <li>고차원 희소데이터에는 잘 안맞는다.</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/16/ML_decision_tree_ensemble_gradientboosting/"><b><code class="language-plaintext highlighter-rouge">그래디언트 부스팅 결정 트리</code></b></a>
    <ul>
      <li>랜덤 포레스트보다 조금 더 성능이 좋다.<br />하지만 랜덤 포레스트보다 학습은 느리나 예측은 빠르고 메모리를 조금 사용한다.</li>
      <li>랜덤 포레스트보다 매개변수 튜닝이 많이 필요하다.</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/22/ML_SVM/"><b><code class="language-plaintext highlighter-rouge">서포트 벡터 머신</code></b></a>
    <ul>
      <li>비슷한 의미의 특성으로 이루어진 중간 규모의 데이터셋에 잘 맞는다.</li>
      <li>데이터 스케일 조정이 무조건 필요하다.</li>
      <li>매개변수에 매우 민감하다.</li>
    </ul>
  </li>
  <li><a href="https://jhryu1208.github.io/data/2020/11/28/ML_uncertainty_of_prediction/"><b><code class="language-plaintext highlighter-rouge">신경망</code></b></a>
    <ul>
      <li>특별히 대용량 데이터셋에서 매우 복잡한 모델을 만들 수 있다.</li>
      <li>서포트 벡터 머신처럼 매개변수 선택과 데이터 스케일에 민감하다.</li>
      <li>큰 모델의 경우 학습이 매우 오래 걸린다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<hr />

<h3 id="references">References</h3>

<ul>
  <li>안드레아스 뮐러, 세라 가이도, 『파이썬 라이브러리를 활용한 머신러닝』, 박해선, 한빛미디어(2017)</li>
</ul>

:ET