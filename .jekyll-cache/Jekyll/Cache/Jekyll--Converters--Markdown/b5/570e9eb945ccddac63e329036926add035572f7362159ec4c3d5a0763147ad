I"q=<h4 id="ml-with-python-4-구간-분할이산화--상호작용다항식">[ML with Python] 4. 구간 분할/이산화 &amp; 상호작용/다항식</h4>
<ul>
  <li>본 포스팅은 구간 분할/이산화 와 상호작용/다항식에 관한 기본적인 내용에 관하여 다룹니다.</li>
</ul>

<h3>Table of Contents<span class="tocSkip"></span></h3>
<div class="toc"><ul class="toc-item"><li><span><a href="#1)-구간-분할,-이산화-그리고-선형-모델,-트리-모델-(-feat.-KBinsDiscretiezer-클래스-)" data-toc-modified-id="1)-구간-분할,-이산화-그리고-선형-모델,-트리-모델-(-feat.-KBinsDiscretiezer-클래스-)-0">1) 구간 분할, 이산화 그리고 선형 모델, 트리 모델 ( feat. KBinsDiscretiezer 클래스 )</a></span></li><li><span><a href="#2)-상호작용" data-toc-modified-id="2)-상호작용-1">2) 상호작용</a></span></li><li><span><a href="#3)-다항식-(-feat.-PolynomialFeatures-)" data-toc-modified-id="3)-다항식-(-feat.-PolynomialFeatures-)-2">3) 다항식 ( feat. PolynomialFeatures )</a></span></li><li><span><a href="#4)-상호작용/다항식-적용-:-보스턴-주택-가격-데이터셋" data-toc-modified-id="4)-상호작용/다항식-적용-:-보스턴-주택-가격-데이터셋-3">4) 상호작용/다항식 적용 : 보스턴 주택 가격 데이터셋</a></span></li><li><span><a href="#5)-References" data-toc-modified-id="5)-References-4">5) References</a></span></li></ul></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126544-83709b80-53a0-11eb-8870-684326136826.JPG" alt="gaga" /></p>

<hr />

<p>필요라이브러리 import</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'axes.unicode_minus'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'font'</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">'Malgun Gothic'</span><span class="p">)</span> 
</code></pre></div></div>

<p><br /></p>

<hr />

<h3 id="1-구간-분할-이산화-그리고-선형-모델-트리-모델--feat-kbinsdiscretiezer-클래스-">1) 구간 분할, 이산화 그리고 선형 모델, 트리 모델 ( feat. KBinsDiscretiezer 클래스 )</h3>

<p>데이터를 가장 잘 표현하는 방법은 <u>데이터가 가진 의미</u> 뿐 아니라 <u>어떤 모델을 사용하는지</u>에 따라 다르다. 폭넓게 사용되어지는 두 알고리즘인 <code class="language-plaintext highlighter-rouge">선형 모델</code>과 <code class="language-plaintext highlighter-rouge">트리 기반 모델</code>은 <u>특성의 표현 방식</u>으로 인해 미치는 영향이 매우 다르다.</p>

<p><br /></p>

<p>입력 특성이 하나 뿐인 wave 데이터셋을 이용해 <code class="language-plaintext highlighter-rouge">선형 회귀 모델</code>과 <code class="language-plaintext highlighter-rouge">결정 트리 회귀</code>를 비교해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">120</span><span class="p">)</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">tree_reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">tree_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'결정 트리'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">line_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'선형 회귀'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x261ab443c08&gt;
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126547-84a1c880-53a0-11eb-88e8-e42b2eca374e.png" alt="ML_segmentation_6_1" /></p>

<p><code class="language-plaintext highlighter-rouge">선형 모델</code>은 선형 관계로만 모델링하므로 특성이 하나일 경우 직선으로만 나타나는 것을 확인할 수 있다. <code class="language-plaintext highlighter-rouge">결정 트리</code>의 경우는 같은 데이터로 복잡한 모델을 만들었다. 그러나 <u>이는 데이터의 표현 형태에 따라 굉장히 달라질 수 있다.</u></p>

<p><br /></p>

<p>연속형 데이터에 아주 강력한 <code class="language-plaintext highlighter-rouge">선형 모델</code>을 만드는 방법 하나는 <u>한 특성을 여러 특성으로 나누는 </u><code class="language-plaintext highlighter-rouge">구간분할(or 이산화)(bining)</code><u>이 있다.</u> 쉽게 말하자면, 연속적인 데이터를 하나의 구간으로 묶는 것이다. <code class="language-plaintext highlighter-rouge">KBinsDiscretizer</code> 클래스를 통하여 이를 구현해보자.</p>

<p><br /></p>

<p>먼저 wave의 input 구간은 “-3 ~ 3(데이터에서 가장 작은 값 : -2.967, 데이터에서 가장 큰 값 : 2.92132162” 이다. 이를 <code class="language-plaintext highlighter-rouge">KBinsDiscreteizer</code>클래스를 이용하여 균일한 너비로 10개의 구간(<code class="language-plaintext highlighter-rouge">n_bis = 10</code>)으로 나누면 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="n">kb</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">)</span>
<span class="n">kb</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#  이때 `bin_edges_` 메소드를 이용하여 저장되어진 경계값을 확인할 수 있다.
</span><span class="k">print</span><span class="p">(</span><span class="s">"bin edges :</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">kb</span><span class="p">.</span><span class="n">bin_edges_</span> <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bin edges :
 [array([-2.9668673 , -2.37804841, -1.78922951, -1.20041062, -0.61159173,
       -0.02277284,  0.56604605,  1.15486494,  1.74368384,  2.33250273,
        2.92132162])]
</code></pre></div></div>

<p><br /></p>

<p><code class="language-plaintext highlighter-rouge">KBinsDiscretizer</code>클래스로 형성된 경계값을 기준으로 형성된 구간마다 다음과 같이 데이터 포인트를 나눌수 있다.</p>
<ul>
  <li>첫 번째 구간은 특성의 값이 -2.967부터 -2.378까지의 모든 데이터 포인트를 담는다.</li>
  <li>두 번째 구간은 특성의 값이 -2.237부터 -1.789까지의 모든 데이터 포인트를 담는다.</li>
  <li>두 번째 구간은 특성의 값이 -1.789부터 -1.200까지의 모든 데이터 포인트를 담는다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_result</span> <span class="o">=</span> <span class="n">kb</span><span class="p">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">X_input</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'property_{0} :'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">X_result</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s">'&lt;= X_input &lt;'</span><span class="p">,</span><span class="n">X_result</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">print</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'X_input값 : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">X_input</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">X_input</span> <span class="o">&gt;=</span> <span class="n">X_result</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">X_input</span> <span class="o">&lt;</span> <span class="n">X_result</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))])</span>
    <span class="k">print</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'------------------------------------------------------------------------------------'</span><span class="p">)</span>

<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'and so on...'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>property_1 : -2.9668672972583856 &lt;= X_input &lt; -2.378048405572237

X_input값 : 
 [-2.9668673  -2.87649303 -2.84748524 -2.81142489 -2.79366887 -2.72863627
 -2.72129752 -2.65149833 -2.6186499  -2.60969044 -2.55573209 -2.55269614
 -2.53812054 -2.46904499 -2.41396732]

------------------------------------------------------------------------------------
property_2 : -2.378048405572237 &lt;= X_input &lt; -1.7892295138860876

X_input값 : 
 [-2.35265144 -2.30478564 -2.28243452 -2.26777059 -2.16303684 -2.15445465
 -2.06403288 -2.06388816 -2.03267228 -1.97685526 -1.9090502  -1.89957294
 -1.89087327 -1.88057965 -1.82410283 -1.80770591 -1.80195731]

------------------------------------------------------------------------------------
property_3 : -1.7892295138860876 &lt;= X_input &lt; -1.2004106221999387

X_input값 : 
 [-1.72596534 -1.62721101 -1.50424663 -1.44732011 -1.37190581 -1.31439294
 -1.26149128 -1.25262516 -1.24713211]

------------------------------------------------------------------------------------

and so on...
</code></pre></div></div>

<p><br /></p>

<p>여기서 <code class="language-plaintext highlighter-rouge">transform</code>메소드를 이용하면 <u>각 데이터 포인트를 해당되는 구간으로 인코딩</u>시킬 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_binned</span> <span class="o">=</span> <span class="n">kb</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_binned</span><span class="p">.</span><span class="n">toarray</span><span class="p">().</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X_binned</span><span class="p">.</span><span class="n">toarray</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(120, 10)





array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_binned</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'property_{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)]</span>
<span class="n">df</span><span class="p">[</span><span class="s">'X_input'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">copy</span><span class="p">().</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'X_input'</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>property_1</th>
      <th>property_2</th>
      <th>property_3</th>
      <th>property_4</th>
      <th>property_5</th>
      <th>property_6</th>
      <th>property_7</th>
      <th>property_8</th>
      <th>property_9</th>
      <th>property_10</th>
    </tr>
    <tr>
      <th>X_input</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-0.752759</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2.704286</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1.391964</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>0.591951</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>-2.063888</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2.228764</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1.822032</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>-1.880580</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2.355354</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>0.236053</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>120 rows × 10 columns</p>
</div>

<p><br /></p>

<p><code class="language-plaintext highlighter-rouge">원-핫-인코딩</code>된 데이터로 <code class="language-plaintext highlighter-rouge">선형 회귀 모델</code>과 <code class="language-plaintext highlighter-rouge">결정 트리 모델</code>을 새로 만들어보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="c1"># 예제를 간단하게 만들기 위해 encode = 'onehot-dense'로 지정하여 원-핫-인코딩된 밀집 행렬로 리턴하여 사용할 것이다.
</span><span class="n">kb</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s">'onehot-dense'</span><span class="p">)</span>
<span class="c1"># wave데이터셋을 학습데이터로 하여금 만든 원-핫-인코딩 배열을 X_binned에 저장
</span><span class="n">kb</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">);</span> <span class="n">X_binned</span> <span class="o">=</span> <span class="n">kb</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># test데이터셋이라고 볼 수 있는 line
</span><span class="n">line_binned</span> <span class="o">=</span> <span class="n">kb</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

<span class="c1"># 특성구간으로 나누어진 train데이터로 각 모델을 학습시킨다.
</span><span class="n">tree_reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">3</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># 학습된 모델을 이용하여 특성구간으로 나누어진 test데이터를 예측
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">tree_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line_binned</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'구간 결정 트리'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">line_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line_binned</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'구간 선형 회귀'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">kb</span><span class="p">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x261a40af9c8&gt;
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126549-853a5f00-53a0-11eb-9f09-aed77bf8e07b.png" alt="ML_segmentation_16_1" /></p>

<p><code class="language-plaintext highlighter-rouge">선형 회귀 모델</code>과 <code class="language-plaintext highlighter-rouge">결정 트리</code>가 같은 예측을 만들어내서 파선과 실선이 완전히 겹쳐진 것을 확인할 수 있다. 구간별로 이 두 모델이 예측한 것은 (실수)상수값이다. 각 구간 안에서는 특성의 값이 상수값이기 때문에 어떤 모델이든 그 구간의 포인트에 대해서는 같은 값을 예측할 것이다.</p>

<p><br /></p>

<p>구간으로 나눈 특성을 사용하기 전과 비교하면, <code class="language-plaintext highlighter-rouge">선형 모델</code>의 경우 <u>매우 유연해진 것</u>을 알 수 있다. 반면 <code class="language-plaintext highlighter-rouge">결정 트리</code>는 <u>덜 유연</u>해졌다. <code class="language-plaintext highlighter-rouge">트리 모델</code>의 경우는 구간으로 나누는 것은 아무런 득이 없지만, <code class="language-plaintext highlighter-rouge">선형 모델</code>은 이러한 변환으로부터 큰 이득을 얻었다.</p>

<p><br /></p>

<p>따라서, 일부 특성과 출력이 <code class="language-plaintext highlighter-rouge">비선형 관계</code>이지만, 용량이 매우 크고 고차원 데이터셋이라 <code class="language-plaintext highlighter-rouge">선형 모델</code>을 사용해야 한다면 <code class="language-plaintext highlighter-rouge">구간 분할</code>이 모델의 성능을 높이는데 아주 탁월한 방법이 될 수 있다.</p>

<p><br /></p>

<hr />

<h3 id="2-상호작용">2) 상호작용</h3>

<p>특성을 풍부하게 나타내는 또 하나의 방법은 원본 데이터에</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">상호작용(interaction)</code></li>
  <li><code class="language-plaintext highlighter-rouge">다항식(polynomial)</code></li>
</ul>

<p>을 추가하는 것이다.</p>

<p><br /></p>

<p>이전의 선형 모델을 <code class="language-plaintext highlighter-rouge">KBinsDiscretizer</code>클래스를 이용해서 wave데이터셋의 각 구간에 대해 상숫값을 학습했었다. 여기서 더 나아가, 이러한 <code class="language-plaintext highlighter-rouge">선형 모델</code><u>은 이런 절편 외에도 <b>기울기</b>도 학습할 수 있다</u>. 선형 모델에 기울기를 추가하는 방법은 <u>구간으로 분할된 데이터에 원래 특성을 다시 추가하는 것</u>이다.</p>

<p><br /></p>

<p>이를 확인하기 위해, 다음 처럼 <code class="language-plaintext highlighter-rouge">hstack</code>을 이용해서 구간별로 상숫값을 학습했던 데이터셋에 원본 특성을 다시 추가해보자. 추가 결과 기존의 10차원 데이터셋에서 11차원 데이터셋으로 증가하였음을 확인할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_combined</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">X_binned</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_combined</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(120, 11)
</code></pre></div></div>

<p><br /></p>

<p>원본 특성을 추가한 데이터셋으로 학습시킨 선형회귀 모델은 각 구간의 <code class="language-plaintext highlighter-rouge">절편(X)</code>과 <code class="language-plaintext highlighter-rouge">기울기(X_binned)</code>를 학습하였다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_combined</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">line_combined</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">line</span><span class="p">,</span> <span class="n">line_binned</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line_combined</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'원본 특성을 더한 선형 회귀'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">kb</span><span class="p">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x261a8e884c8&gt;]
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126550-853a5f00-53a0-11eb-87b6-7a3ce268c1d1.png" alt="ML_segmentation_22_1" /></p>

<p><br /></p>

<p>학습된 기울기는 모든 구간에 걸쳐 동일 하지만, 이러한 모든 구간에서 동일하기에 큰 이점은 없다. <u>오히려 각 구간에서 다른 기울기를 가지는 것이 더 이점이 있다</u>. 이러한 효과를 보기위해서는 <code class="language-plaintext highlighter-rouge">데이터 포인트가 있는 구간(X_binned)</code>과 <code class="language-plaintext highlighter-rouge">x축 사이의 상호작용 특성(구간 특성&lt;X_binned&gt; * 원본 특성&lt;X&gt;)</code>을 추가할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_product</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X_binned</span><span class="p">,</span> <span class="n">X</span><span class="o">*</span><span class="n">X_binned</span><span class="p">])</span>
<span class="c1"># 데이터셋은 데이터 포인트가 속한 구간과 이 구간에 원본 특성을 곱한 값을 더해 20개의 특성을 가지게된다.
</span><span class="k">print</span><span class="p">(</span><span class="n">X_product</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(120, 20)
</code></pre></div></div>

<p><br /></p>

<p>데이터 포인트가 속한 구간과 원본 특성을 곱한 값(X*X_binned)은 구간 안에서는 원본 특성이고 다른 곳에서는 0인 것을 확인할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">*</span><span class="n">X_binned</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'property_{0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)]</span>
<span class="n">df</span><span class="p">[</span><span class="s">'X_input'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">copy</span><span class="p">().</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'X_input'</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>property_1</th>
      <th>property_2</th>
      <th>property_3</th>
      <th>property_4</th>
      <th>property_5</th>
      <th>property_6</th>
      <th>property_7</th>
      <th>property_8</th>
      <th>property_9</th>
      <th>property_10</th>
    </tr>
    <tr>
      <th>X_input</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-0.752759</th>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.0</td>
      <td>-0.752759</td>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>2.704286</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.704286</td>
    </tr>
    <tr>
      <th>1.391964</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.391964</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>0.591951</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.591951</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>-2.063888</th>
      <td>-0.0</td>
      <td>-2.063888</td>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2.228764</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.228764</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1.822032</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.822032</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>-1.880580</th>
      <td>-0.0</td>
      <td>-1.880580</td>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.0</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>2.355354</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.355354</td>
    </tr>
    <tr>
      <th>0.236053</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.236053</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>120 rows × 10 columns</p>
</div>

<p><br /></p>

<p>아래는 이 데이터를 사용해 만든 선형 모델의 결과이다. <br />
아래 그림에서 볼 수 있듯이 이 모델에서는 각 구간에서 절편과 기울기가 모두 다르다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_product</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">line_product</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">line_binned</span><span class="p">,</span> <span class="n">line</span><span class="o">*</span><span class="n">line_binned</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line_product</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'원본 특성을 곱한 선형 회귀'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">kb</span><span class="p">.</span><span class="n">bin_edges_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x261aa66a788&gt;]
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126553-85d2f580-53a0-11eb-8885-2a57f88067f9.png" alt="ML_segmentation_28_1" /></p>

<p><br /></p>

<hr />

<h3 id="3-다항식--feat-polynomialfeatures-">3) 다항식 ( feat. PolynomialFeatures )</h3>

<p>특성을 풍부하게 나타내는 또 하나의 방법에는 이전에 언급했던 것과 같이 <code class="language-plaintext highlighter-rouge">상호작용</code>뿐만 아니라 원본 특성의 <code class="language-plaintext highlighter-rouge">다항식</code>을 추가하는 방법도 있다. 예를 들자면, <code class="language-plaintext highlighter-rouge">x^2</code>, <code class="language-plaintext highlighter-rouge">x^3</code>, <code class="language-plaintext highlighter-rouge">x^4</code>와 같은 특성을 추가하는 것이다. 해당 방식은 <code class="language-plaintext highlighter-rouge">preprocessing</code> 모듈의 <code class="language-plaintext highlighter-rouge">PolynomialFeatures</code>에 구현되어있다. wave데이터셋에 <code class="language-plaintext highlighter-rouge">PolynomialFeatures</code>를 사용해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1"># x^10까지 고차항을 추가한다.
# 기본값인 "include_bias = True"는 절편에 해당하는 1인 특성을 추가한다.
</span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">poly</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 10차원까지 고차항을 추가하였기 때문에 10개의 특성이 만들어진다.
</span><span class="k">print</span><span class="p">(</span><span class="s">"X_poly.shape: "</span><span class="p">,</span> <span class="n">X_poly</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X_poly.shape:  (120, 10)
</code></pre></div></div>

<p><br /></p>

<p>X와 X_poly값을 비교하면 다음과 같다. index인 x_input은 기존 wave데이터셋의 데이터포인트를 의미하며, 각 열은 해당 데이터포인트의 거듭제곱을 나타낸다. 예를들어 x0의 경우 (x_input)^1, x0^2의 경우 (x_input)^2에 해당한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_poly</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_poly</span><span class="p">)</span>
<span class="n">df_poly</span><span class="p">[</span><span class="s">'x_input'</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span>

<span class="c1">#각 특성의 차수를 알려주는 get_feature_names메서드를 사용해 특성의 의미를 알 수 있다.
</span><span class="n">column_name</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="n">column_name</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">'x_input'</span><span class="p">)</span>
<span class="n">df_poly</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">column_name</span>

<span class="n">df_poly</span> <span class="o">=</span> <span class="n">df_poly</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'x_input'</span><span class="p">)</span>
<span class="n">df_poly</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x0</th>
      <th>x0^2</th>
      <th>x0^3</th>
      <th>x0^4</th>
      <th>x0^5</th>
      <th>x0^6</th>
      <th>x0^7</th>
      <th>x0^8</th>
      <th>x0^9</th>
      <th>x0^10</th>
    </tr>
    <tr>
      <th>x_input</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>-0.752759</th>
      <td>-0.752759</td>
      <td>0.566647</td>
      <td>-0.426548</td>
      <td>0.321088</td>
      <td>-0.241702</td>
      <td>0.181944</td>
      <td>-0.136960</td>
      <td>0.103098</td>
      <td>-0.077608</td>
      <td>5.841996e-02</td>
    </tr>
    <tr>
      <th>2.704286</th>
      <td>2.704286</td>
      <td>7.313162</td>
      <td>19.776880</td>
      <td>53.482337</td>
      <td>144.631526</td>
      <td>391.124988</td>
      <td>1057.713767</td>
      <td>2860.360362</td>
      <td>7735.232021</td>
      <td>2.091828e+04</td>
    </tr>
    <tr>
      <th>1.391964</th>
      <td>1.391964</td>
      <td>1.937563</td>
      <td>2.697017</td>
      <td>3.754150</td>
      <td>5.225640</td>
      <td>7.273901</td>
      <td>10.125005</td>
      <td>14.093639</td>
      <td>19.617834</td>
      <td>2.730731e+01</td>
    </tr>
    <tr>
      <th>0.591951</th>
      <td>0.591951</td>
      <td>0.350406</td>
      <td>0.207423</td>
      <td>0.122784</td>
      <td>0.072682</td>
      <td>0.043024</td>
      <td>0.025468</td>
      <td>0.015076</td>
      <td>0.008924</td>
      <td>5.282711e-03</td>
    </tr>
    <tr>
      <th>-2.063888</th>
      <td>-2.063888</td>
      <td>4.259634</td>
      <td>-8.791409</td>
      <td>18.144485</td>
      <td>-37.448187</td>
      <td>77.288869</td>
      <td>-159.515582</td>
      <td>329.222321</td>
      <td>-679.478050</td>
      <td>1.402367e+03</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2.228764</th>
      <td>2.228764</td>
      <td>4.967387</td>
      <td>11.071131</td>
      <td>24.674933</td>
      <td>54.994591</td>
      <td>122.569939</td>
      <td>273.179411</td>
      <td>608.852310</td>
      <td>1356.987831</td>
      <td>3.024405e+03</td>
    </tr>
    <tr>
      <th>1.822032</th>
      <td>1.822032</td>
      <td>3.319802</td>
      <td>6.048788</td>
      <td>11.021087</td>
      <td>20.080779</td>
      <td>36.587831</td>
      <td>66.664215</td>
      <td>121.464364</td>
      <td>221.312014</td>
      <td>4.032377e+02</td>
    </tr>
    <tr>
      <th>-1.880580</th>
      <td>-1.880580</td>
      <td>3.536580</td>
      <td>-6.650820</td>
      <td>12.507397</td>
      <td>-23.521156</td>
      <td>44.233407</td>
      <td>-83.184444</td>
      <td>156.434973</td>
      <td>-294.188426</td>
      <td>5.532448e+02</td>
    </tr>
    <tr>
      <th>2.355354</th>
      <td>2.355354</td>
      <td>5.547692</td>
      <td>13.066779</td>
      <td>30.776891</td>
      <td>72.490474</td>
      <td>170.740726</td>
      <td>402.154851</td>
      <td>947.217033</td>
      <td>2231.031419</td>
      <td>5.254869e+03</td>
    </tr>
    <tr>
      <th>0.236053</th>
      <td>0.236053</td>
      <td>0.055721</td>
      <td>0.013153</td>
      <td>0.003105</td>
      <td>0.000733</td>
      <td>0.000173</td>
      <td>0.000041</td>
      <td>0.000010</td>
      <td>0.000002</td>
      <td>5.371599e-07</td>
    </tr>
  </tbody>
</table>
<p>120 rows × 10 columns</p>
</div>

<p><br /></p>

<p>위와 같은 <code class="language-plaintext highlighter-rouge">다항식 특성</code>을 <code class="language-plaintext highlighter-rouge">선형 모델</code>과 함께 사용하면 전형적인 <code class="language-plaintext highlighter-rouge">다항 회귀(polynomial regression)</code>모델이 된다. 다항식 특성은 1차원 데이터셋에서도 매우 부드러운 곡선을 만든다. 그러나 <u>(주의) 고차원 다항식은 데이터가 부족한 영역에서는 너무 민감하게 동작할 때가 있다</u>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">line_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line_poly</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'다항 회귀'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># 비교를 위해 아무런 변환도 거치지 않은 원본 데이터에 `커널SVM`모델을 학습시켜보았다.
</span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>

<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
    <span class="n">svr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">svr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line</span><span class="p">),</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'SVR gamma={0}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">gamma</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'회귀 출력'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'입력 특성'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/104126554-85d2f580-53a0-11eb-869c-0d4e48af7086.png" alt="ML_segmentation_35_0" /></p>

<p><img src="https://user-images.githubusercontent.com/53929665/104126555-866b8c00-53a0-11eb-9b88-427dfc55dea4.png" alt="ML_segmentation_35_1" /></p>

<p><br /></p>

<h3 id="4-상호작용다항식-적용--보스턴-주택-가격-데이터셋">4) 상호작용/다항식 적용 : 보스턴 주택 가격 데이터셋</h3>

<p><code class="language-plaintext highlighter-rouge">상호작용</code>과 <code class="language-plaintext highlighter-rouge">다항식</code>을 실제로 적용해보기 위해 보스턴 주택 가격 데이터셋을 이용할 것이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 데이터 로드
</span><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>

<span class="c1"># test데이터셋 train데이터셋 분류 
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">boston</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">df_boston</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">boston</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">df_boston</span><span class="p">[</span><span class="s">'target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">boston</span><span class="p">.</span><span class="n">target</span>
<span class="n">df_boston</span> <span class="o">=</span> <span class="n">df_boston</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'target'</span><span class="p">)</span>
<span class="n">df_boston</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
    </tr>
    <tr>
      <th>target</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24.0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
    </tr>
    <tr>
      <th>21.6</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
    </tr>
    <tr>
      <th>34.7</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
    </tr>
    <tr>
      <th>33.4</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
    </tr>
    <tr>
      <th>36.2</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>22.4</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
    </tr>
    <tr>
      <th>20.6</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
    </tr>
    <tr>
      <th>23.9</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
    </tr>
    <tr>
      <th>22.0</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
    </tr>
    <tr>
      <th>11.9</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 13 columns</p>
</div>

<p><br /></p>

<p>먼저 <code class="language-plaintext highlighter-rouge">MinMaxScaler</code>를 사용해 스케일을 0에서 1사이로 조정한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">df_train_boston</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">df_train_boston</span><span class="p">[</span><span class="s">'train_target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="n">df_train_boston</span> <span class="o">=</span> <span class="n">df_train_boston</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'train_target'</span><span class="p">)</span>
<span class="n">df_train_boston</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
    </tr>
    <tr>
      <th>train_target</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>18.5</th>
      <td>0.002079</td>
      <td>0.22</td>
      <td>0.197947</td>
      <td>0.0</td>
      <td>0.094650</td>
      <td>0.391646</td>
      <td>0.693100</td>
      <td>0.619112</td>
      <td>0.260870</td>
      <td>0.272901</td>
      <td>0.691489</td>
      <td>0.980407</td>
      <td>0.474610</td>
    </tr>
    <tr>
      <th>19.6</th>
      <td>0.001090</td>
      <td>0.25</td>
      <td>0.171188</td>
      <td>0.0</td>
      <td>0.139918</td>
      <td>0.453344</td>
      <td>0.456231</td>
      <td>0.525716</td>
      <td>0.304348</td>
      <td>0.185115</td>
      <td>0.755319</td>
      <td>1.000000</td>
      <td>0.212482</td>
    </tr>
    <tr>
      <th>33.2</th>
      <td>0.001106</td>
      <td>0.40</td>
      <td>0.218109</td>
      <td>1.0</td>
      <td>0.127572</td>
      <td>0.710098</td>
      <td>0.474768</td>
      <td>0.329885</td>
      <td>0.130435</td>
      <td>0.127863</td>
      <td>0.531915</td>
      <td>0.980710</td>
      <td>0.122553</td>
    </tr>
    <tr>
      <th>13.1</th>
      <td>0.097903</td>
      <td>0.00</td>
      <td>0.646628</td>
      <td>0.0</td>
      <td>0.633745</td>
      <td>0.557578</td>
      <td>0.987642</td>
      <td>0.050355</td>
      <td>1.000000</td>
      <td>0.914122</td>
      <td>0.808511</td>
      <td>0.987594</td>
      <td>0.436596</td>
    </tr>
    <tr>
      <th>7.5</th>
      <td>0.121703</td>
      <td>0.00</td>
      <td>0.646628</td>
      <td>0.0</td>
      <td>0.604938</td>
      <td>0.617168</td>
      <td>0.905252</td>
      <td>0.058919</td>
      <td>1.000000</td>
      <td>0.914122</td>
      <td>0.808511</td>
      <td>0.053583</td>
      <td>0.682553</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>18.5</th>
      <td>0.003120</td>
      <td>0.00</td>
      <td>0.253666</td>
      <td>0.0</td>
      <td>0.222222</td>
      <td>0.411381</td>
      <td>0.735324</td>
      <td>0.323850</td>
      <td>0.173913</td>
      <td>0.190840</td>
      <td>0.744681</td>
      <td>0.985451</td>
      <td>0.283972</td>
    </tr>
    <tr>
      <th>36.4</th>
      <td>0.000903</td>
      <td>0.45</td>
      <td>0.109238</td>
      <td>0.0</td>
      <td>0.106996</td>
      <td>0.693045</td>
      <td>0.240989</td>
      <td>0.484428</td>
      <td>0.173913</td>
      <td>0.402672</td>
      <td>0.276596</td>
      <td>0.983837</td>
      <td>0.032340</td>
    </tr>
    <tr>
      <th>19.2</th>
      <td>0.001626</td>
      <td>0.00</td>
      <td>0.350073</td>
      <td>0.0</td>
      <td>0.333333</td>
      <td>0.471355</td>
      <td>0.820803</td>
      <td>0.143641</td>
      <td>0.217391</td>
      <td>0.467557</td>
      <td>0.553191</td>
      <td>0.993973</td>
      <td>0.243121</td>
    </tr>
    <tr>
      <th>16.6</th>
      <td>0.002506</td>
      <td>0.00</td>
      <td>0.236437</td>
      <td>0.0</td>
      <td>0.129630</td>
      <td>0.473079</td>
      <td>0.850669</td>
      <td>0.412260</td>
      <td>0.086957</td>
      <td>0.087786</td>
      <td>0.563830</td>
      <td>0.989510</td>
      <td>0.484255</td>
    </tr>
    <tr>
      <th>23.1</th>
      <td>0.001493</td>
      <td>0.00</td>
      <td>0.131598</td>
      <td>0.0</td>
      <td>0.257202</td>
      <td>0.385323</td>
      <td>0.881565</td>
      <td>0.129827</td>
      <td>0.173913</td>
      <td>0.208015</td>
      <td>0.425532</td>
      <td>1.000000</td>
      <td>0.367660</td>
    </tr>
  </tbody>
</table>
<p>379 rows × 13 columns</p>
</div>

<p><br /></p>

<p>이제 차수를 2로 하여 다항식 특성을 뽑는다. 해당 데이터는 기존에는 특성이 13개 였는데, 다항식 특성을 추가하여 105개까지 교차 특성으로 확장된 것을 확인할 수 있다. <u> 새로운 특성은 원래 특성의 제곱은 물론 가능한 두 특성의 조합을 모두 포함한다</u>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_train_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="n">X_test_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"X_train.shape : "</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"X_train_poly.shape : "</span><span class="p">,</span> <span class="n">X_train_poly</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'다항 특성 이름 : </span><span class="se">\n</span><span class="s">'</span><span class="p">,</span> <span class="n">poly</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X_train.shape :  (379, 13)
X_train_poly.shape :  (379, 105)

다항 특성 이름 : 
 ['1', 'x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x0^2', 'x0 x1', 'x0 x2', 'x0 x3', 'x0 x4', 'x0 x5', 'x0 x6', 'x0 x7', 'x0 x8', 'x0 x9', 'x0 x10', 'x0 x11', 'x0 x12', 'x1^2', 'x1 x2', 'x1 x3', 'x1 x4', 'x1 x5', 'x1 x6', 'x1 x7', 'x1 x8', 'x1 x9', 'x1 x10', 'x1 x11', 'x1 x12', 'x2^2', 'x2 x3', 'x2 x4', 'x2 x5', 'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x2 x11', 'x2 x12', 'x3^2', 'x3 x4', 'x3 x5', 'x3 x6', 'x3 x7', 'x3 x8', 'x3 x9', 'x3 x10', 'x3 x11', 'x3 x12', 'x4^2', 'x4 x5', 'x4 x6', 'x4 x7', 'x4 x8', 'x4 x9', 'x4 x10', 'x4 x11', 'x4 x12', 'x5^2', 'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x5 x11', 'x5 x12', 'x6^2', 'x6 x7', 'x6 x8', 'x6 x9', 'x6 x10', 'x6 x11', 'x6 x12', 'x7^2', 'x7 x8', 'x7 x9', 'x7 x10', 'x7 x11', 'x7 x12', 'x8^2', 'x8 x9', 'x8 x10', 'x8 x11', 'x8 x12', 'x9^2', 'x9 x10', 'x9 x11', 'x9 x12', 'x10^2', 'x10 x11', 'x10 x12', 'x11^2', 'x11 x12', 'x12^2']
</code></pre></div></div>

<p><br /></p>

<p><code class="language-plaintext highlighter-rouge">상호작용 특성이 있는 데이터</code>와 <code class="language-plaintext highlighter-rouge">없는 데이터</code>에 대해 <code class="language-plaintext highlighter-rouge">Ridge</code>를 사용해 성능을 비교해보았을 때 상호작용 특성을 넣은 경우의 score가 높은 것을 확인할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"상호작용 특성이 없을 때 점수: {:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ridge</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_poly</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"상호작용 특성이 있을 때 점수: {:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ridge</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_poly</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>상호작용 특성이 없을 때 점수: 0.577
상호작용 특성이 있을 때 점수: 0.741
</code></pre></div></div>

<p><br /></p>

<p>하지만, <code class="language-plaintext highlighter-rouge">랜덤 포레스트</code>와 같이 <u>복잡한 모델에서 </u><code class="language-plaintext highlighter-rouge">상호작용</code><u>을 사용하면 오히려 점수가 떨어지는 것</u>을 확인할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"상호작용 특성이 없을 때 점수: {:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_poly</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"상호작용 특성이 있을 때 점수: {:.3f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_poly</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>상호작용 특성이 없을 때 점수: 0.785
상호작용 특성이 있을 때 점수: 0.761
</code></pre></div></div>

<p><br /></p>

<hr />

<h3 id="5-references">5) References</h3>

<ul>
  <li>안드레아스 뮐러, 세라 가이도, 『파이썬 라이브러리를 활용한 머신러닝』, 박해선, 한빛미디어(2017)</li>
</ul>

:ET