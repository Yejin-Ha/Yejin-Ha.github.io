I":<h4 id="ml-with-python-2-지도-학습-알고리즘-2-선형-모델---선형회귀">[ML with Python] 2. 지도 학습 알고리즘 (2) 선형 모델 - 선형회귀</h4>
<ul>
  <li>본 포스팅은 지도 학습 알고리즘인 선형 모델에 관한 기본적인 내용에 관하여 다룹니다.</li>
  <li>선형회귀( <code class="language-plaintext highlighter-rouge">LinearRegression</code> ),  최소제곱법( <code class="language-plaintext highlighter-rouge">OLS</code> )</li>
</ul>

<hr />

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">mglearn</span>
</code></pre></div></div>

<h3 id="선형모델"><u>선형모델</u></h3>

<p><code class="language-plaintext highlighter-rouge">선형 모델</code>은 입력 특성에 대한 <code class="language-plaintext highlighter-rouge">선형 함수</code>를 만들어 예측을 수행한다.</p>

<hr />

<h4 id="회귀의-선형-모델"><u>회귀의 선형 모델</u></h4>

<p>회귀의 경우 선형 모델을 위한 일반화된 예측 함수는 다음과 같다.</p>

<blockquote>
  <p>ŷ = w[0] × x[0] + w[1] × x[1] + … + w[p] × x[p] + b</p>
</blockquote>

<p>이 식에서 <code class="language-plaintext highlighter-rouge">x[0] ~ x[p]</code>까지 하나의 <b>데이터 포인트에 대한 특성</b>을 나타내며(특성의 개수는 p+1개)<br />
<code class="language-plaintext highlighter-rouge">w</code>와 <code class="language-plaintext highlighter-rouge">b</code>는 모델이 <b>학습할 파라미터</b>이다.<br />
마지막으로 <code class="language-plaintext highlighter-rouge">ŷ</code>는 모델이 만들어낸 <b>예측값</b>이다.</p>

<p><br /></p>

<p>만약 특성이 하나인 데이터셋이라면 이 식은 다음과 같아진다.</p>

<blockquote>
  <p>ŷ = w[0] × x[0] + b</p>
</blockquote>

<p>이 식에서 <code class="language-plaintext highlighter-rouge">w[0]</code>는 기울기고 <code class="language-plaintext highlighter-rouge">b</code>는 y축과 만나는 절편이다.<br />
특성이 많아지면 <code class="language-plaintext highlighter-rouge">w</code>는 <u>각 특성에 해당하는 기울기를 모두 가지게되는 것</u>이다!<br />
다르게 생각하면 <b>예측값</b>은 입력 특성 <code class="language-plaintext highlighter-rouge">w</code>의 <u>각 가중치를 곱해서 더한 가중치합</u>으로 볼 수 있다.</p>

<p>이제 1차원 <code class="language-plaintext highlighter-rouge">wave 데이터셋</code>으로 파라미터 <code class="language-plaintext highlighter-rouge">w[0]</code>와 <code class="language-plaintext highlighter-rouge">b</code>를 직선처럼 학습시켜보면 다음과 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="n">plot_linear_regression_wave</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>w[0]: 0.393906  b: -0.031804
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/53929665/98557517-aa024f80-22e7-11eb-81eb-7df7ada9a6cf.png" alt="linear_model_LinearRegression_5_1" /></p>

<p>직선 방정식을 이해하기 쉽도록 그래프의 중앙을 가로질러서 x, y축이 그려져있다.<br /></p>

<p>회귀를 위한 선형모델은</p>

<ul>
  <li>특성 한개 -&gt; 직선</li>
  <li>특성 두개 -&gt; 평면</li>
  <li>더 많은 특성 -&gt; 초평면(hyperplane)</li>
</ul>

<p>이 되는 회귀 모델의 특징을 가지고 있다.</p>

<p>특히 <u>특성이 많은 데이터셋</u>이라면 <code class="language-plaintext highlighter-rouge">선형 모델</code>은 매우 휼륭한 성능을 낼 수 있다.<br />
<u>훈련 데이터보다 특성이 더 많은 경우</u>엔 어떤 타깃 y도 완벽하게 (훈련 세트에 대해서) 선형 함수로 모델링할 수 있다.</p>

<p>회귀를 위한 선형 모델은 다양하다.<br />
이 모델들은 훈련 데이터로부터 모델 파라미터 <code class="language-plaintext highlighter-rouge">w</code>와 <code class="language-plaintext highlighter-rouge">b</code>를 <u>(1)학습하는 방법</u>과 <u>(2)모델의 복잡도를 제어하는 방법</u>에서 차이가 난다. 회귀에서 가장 인기 있는 선형 모델들을 살펴보자</p>

<hr />

<h4 id="선형-회귀최소제곱법"><u>선형 회귀(최소제곱법)</u></h4>

<p><code class="language-plaintext highlighter-rouge">선형회귀(linear regression)</code>또는 <code class="language-plaintext highlighter-rouge">최소제곱법(OLS, ordinary least squares)</code>는 가장 간단하고 오래된 회귀용 선형 알고리즘이다.<br /></p>

<p><code class="language-plaintext highlighter-rouge">선형회귀</code>는 예측과 훈련 세트에 있는 타깃 y 사이의 <u>`평균제곱오차(mean squared error)`를 최소화하는</u> 파라미터 <code class="language-plaintext highlighter-rouge">w</code>와 <code class="language-plaintext highlighter-rouge">b</code>를 찾는다.(<code class="language-plaintext highlighter-rouge">평균제곱오차</code>는 <b>예측값</b>과 <b>타깃값</b>의 차이를 제곱하여 더한 후에 샘플의 개수로 나눈 것이다.)</p>

<p><u>`선형회귀`는 매개변수가 없는 것이 장점이지만, 그래서 모델의 복잡도를 제어할 방법이 없다.</u></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<p>여기서!<br /></p>
<ul>
  <li><b>기울기 파라미터(<code class="language-plaintext highlighter-rouge">w</code>)</b>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">가중치(weight)</code> 또는 <code class="language-plaintext highlighter-rouge">계수(coefficient)</code>라고 한다.</li>
      <li>Ir객체의 <code class="language-plaintext highlighter-rouge">coef_</code>속성에 저장되어 있다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><b>절편(intercept) 파라미터(<code class="language-plaintext highlighter-rouge">b</code>)</b>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">편향(offset)</code>을 의미하기도 한다.</li>
      <li>Ir객체의 <code class="language-plaintext highlighter-rouge">intercept_</code>속성에 저장되어 있다.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'lr.coef_ : '</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'lr.intercept_ : '</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lr.coef_ :  [0.39390555]
lr.intercept_ :  -0.031804343026759746
</code></pre></div></div>

<blockquote>
  <p>intercept_ 속성은 항상 실수float 값 하나지만, coef_ 속성은 각 입력 특성에 하나씩 대응되는 NumPy 배열입니다. wave 데이터셋에는 입력 특성이 하나뿐이므로 lr.coef_도 원소를 하나만 가지고 있습니다.</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">훈련 세트</code>와 <code class="language-plaintext highlighter-rouge">테스트 세트</code>의 성능을 확인해보자</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"훈련 세트 점수: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"테스트 세트 점수: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>훈련 세트 점수: 0.67
테스트 세트 점수: 0.66
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">R2</code>값이 0.66인 것은 그리 좋은 결과에 속하지 않는다.<br />
하지만 <code class="language-plaintext highlighter-rouge">훈련 세트</code>와 <code class="language-plaintext highlighter-rouge">테스트 세트</code>의 점수가 매우 비슷한 것을 알 수 있다.<br />
이는 과대적합이아니라 <code class="language-plaintext highlighter-rouge">과소적합</code> 상태를 의미한다.</p>

<p>위와 같은 1차원 데이터셋에서는 모델이 매우 단순하므로 과대적합을 걱정할 필요가 없다.<br />
그러나, <u>특성이 많은 고차원 데이터셋에서는 선형 모델의 성능이 매우 높아져 과대적합될 가능성이 높다.</u></p>

<p>그렇다면, <code class="language-plaintext highlighter-rouge">LinearRegression</code>모델이 복잡한 보스턴 주택가격 데이터셋에서는 어떻게 동작하는지 확인해보자</p>

<p>먼저 데이터셋을 읽고 <code class="language-plaintext highlighter-rouge">훈련 세트</code>와 <code class="language-plaintext highlighter-rouge">테스트 세트</code>로 나누고, 이전과 같은 방식으로 선형모델을 만들자</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">load_extended_boston</span><span class="p">()</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"훈련 세트 점수: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"테스트 세트 점수: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>훈련 세트 점수: 0.95
테스트 세트 점수: 0.61
</code></pre></div></div>

<p>이번에는 전의 예제와 다르게 <code class="language-plaintext highlighter-rouge">훈련 세트</code>에서는 매우 정확한 반면, <code class="language-plaintext highlighter-rouge">테스트 세트</code>에서는 매우 낮습니다.<br />
즉, <u>이는 모델이 `과대적합`되었다는 확실한 신호이므로 복잡도를 제어할 수 있는 모델을 사용해야한다.</u></p>

<p>따라서, 다음으로 볼 모델은 <code class="language-plaintext highlighter-rouge">리지 회귀</code>이다.</p>

<hr />

<h3 id="references">References</h3>

<ul>
  <li>안드레아스 뮐러, 세라 가이도, 『파이썬 라이브러리를 활용한 머신러닝』, 박해선, 한빛미디어(2017)</li>
  <li><a href="https://tensorflow.blog/%ed%8c%8c%ec%9d%b4%ec%8d%ac-%eb%a8%b8%ec%8b%a0%eb%9f%ac%eb%8b%9d/2-3-3-%ec%84%a0%ed%98%95-%eb%aa%a8%eb%8d%b8/">https://tensorflow.blog/파이썬-머신러닝/2-3-3-선형-모델/</a></li>
</ul>

:ET